{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ASVspoof 2019 LA – Multi-branch Attention Model\n",
        "\n",
        "Notebook này tái cấu trúc toàn bộ project huấn luyện mô hình đa nhánh phát hiện giả mạo giọng nói sang định dạng `.ipynb` để có thể chạy trực tiếp trên Kaggle hoặc các môi trường notebook khác. Mọi phần mã nguồn trong thư mục `src/` và script `train.py` đều đã được tổ chức lại thành các cell có chú thích rõ ràng."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Chuẩn bị môi trường\n",
        "Chạy cell bên dưới để cài đặt các phụ thuộc cần thiết. Bạn có thể tuỳ chỉnh danh sách nếu môi trường đã có sẵn một số thư viện."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Nếu chạy trên Kaggle hoặc môi trường mới, bỏ comment dòng dưới để cài đặt.\n",
        "# !pip install torch torchaudio numpy scipy pandas PyYAML librosa soundfile tqdm matplotlib tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Thư viện và cấu hình toàn cục"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import csv\n",
        "import math\n",
        "import os\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, List, Optional, Tuple, TypedDict, Any\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchaudio\n",
        "import yaml\n",
        "from torch import Tensor\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Đảm bảo reproducibility (có thể điều chỉnh tuỳ nhu cầu)\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Cấu hình đặc trưng và xử lý âm thanh\n",
        "Các cell dưới đây tương ứng với `src/data/features.py` và `src/utils/audio.py`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class SpectralConfig(TypedDict, total=False):\n",
        "    n_fft: int\n",
        "    hop_length: int\n",
        "    win_length: int\n",
        "    n_mels: int\n",
        "    f_min: float\n",
        "    f_max: Optional[float]\n",
        "    power: float\n",
        "\n",
        "\n",
        "class TemporalConfig(TypedDict, total=False):\n",
        "    emphasis: bool\n",
        "    highpass_cutoff: float\n",
        "\n",
        "\n",
        "class CepstralConfig(TypedDict, total=False):\n",
        "    hop_length: int\n",
        "    n_bins: int\n",
        "    bins_per_octave: int\n",
        "    f_min: float\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class FeatureConfig:\n",
        "    \"\"\"Tập hợp các tham số dựng đặc trưng cho từng nhánh.\"\"\"\n",
        "\n",
        "    sample_rate: int = 16000\n",
        "    spectral: SpectralConfig = field(\n",
        "        default_factory=lambda: SpectralConfig(\n",
        "            n_fft=1024,\n",
        "            hop_length=256,\n",
        "            win_length=1024,\n",
        "            n_mels=128,\n",
        "            f_min=20.0,\n",
        "            f_max=None,\n",
        "            power=2.0,\n",
        "        )\n",
        "    )\n",
        "    temporal: TemporalConfig = field(\n",
        "        default_factory=lambda: TemporalConfig(\n",
        "            emphasis=True,\n",
        "            highpass_cutoff=30.0,\n",
        "        )\n",
        "    )\n",
        "    cepstral: CepstralConfig = field(\n",
        "        default_factory=lambda: CepstralConfig(\n",
        "            hop_length=256,\n",
        "            n_bins=84,\n",
        "            bins_per_octave=12,\n",
        "            f_min=32.7,\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def ensure_mono(waveform: Tensor) -> Tensor:\n",
        "    \"\"\"Chuyển waveform nhiều kênh về mono bằng cách trung bình theo trục kênh.\"\"\"\n",
        "    if waveform.size(0) == 1:\n",
        "        return waveform\n",
        "    return waveform.mean(dim=0, keepdim=True)\n",
        "\n",
        "\n",
        "def load_audio(path: str, target_sample_rate: int, normalize: bool = True) -> Tuple[Tensor, int]:\n",
        "    \"\"\"Đọc audio, resample nếu cần và chuẩn hoá biên độ về [-1, 1].\"\"\"\n",
        "    waveform, sample_rate = torchaudio.load(path)\n",
        "    if sample_rate != target_sample_rate:\n",
        "        resampler = torchaudio.transforms.Resample(sample_rate, target_sample_rate)\n",
        "        waveform = resampler(waveform)\n",
        "        sample_rate = target_sample_rate\n",
        "\n",
        "    waveform = ensure_mono(waveform)\n",
        "    if normalize:\n",
        "        peak = waveform.abs().max()\n",
        "        if peak > 0:\n",
        "            waveform = waveform / peak\n",
        "    return waveform, sample_rate\n",
        "\n",
        "\n",
        "def pad_or_trim(waveform: Tensor, target_num_samples: int, mode: str = \"repeat\") -> Tensor:\n",
        "    \"\"\"Đưa waveform về độ dài cố định bằng cách pad hoặc cắt.\"\"\"\n",
        "    current = waveform.size(-1)\n",
        "    if current == target_num_samples:\n",
        "        return waveform\n",
        "    if current > target_num_samples:\n",
        "        return waveform[..., :target_num_samples]\n",
        "\n",
        "    diff = target_num_samples - current\n",
        "    if mode == \"zeros\":\n",
        "        padded = torch.nn.functional.pad(waveform, (0, diff))\n",
        "    elif mode == \"reflect\":\n",
        "        padded = torch.nn.functional.pad(waveform, (0, diff), mode=\"reflect\")\n",
        "    elif mode == \"repeat\":\n",
        "        repeats = math.ceil(target_num_samples / current)\n",
        "        padded = waveform.repeat(1, repeats)[..., :target_num_samples]\n",
        "    else:\n",
        "        raise ValueError(f\"pad_mode không được hỗ trợ: {mode}\")\n",
        "    return padded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "MultiBranchFeatures = Dict[str, Tensor]\n",
        "\n",
        "\n",
        "class MultiBranchFeatureExtractor:\n",
        "    \"\"\"Sinh đặc trưng cho ba nhánh: spectral (Mel), temporal (sóng), cepstral (CQT).\"\"\"\n",
        "\n",
        "    def __init__(self, config: FeatureConfig) -> None:\n",
        "        self.config = config\n",
        "        spec_cfg = config.spectral\n",
        "        self.mel_transform = torchaudio.transforms.MelSpectrogram(\n",
        "            sample_rate=config.sample_rate,\n",
        "            n_fft=spec_cfg.get(\"n_fft\", 1024),\n",
        "            hop_length=spec_cfg.get(\"hop_length\", 256),\n",
        "            win_length=spec_cfg.get(\"win_length\", spec_cfg.get(\"n_fft\", 1024)),\n",
        "            f_min=spec_cfg.get(\"f_min\", 20.0),\n",
        "            f_max=spec_cfg.get(\"f_max\"),\n",
        "            n_mels=spec_cfg.get(\"n_mels\", 128),\n",
        "            power=spec_cfg.get(\"power\", 2.0),\n",
        "            normalized=False,\n",
        "        )\n",
        "\n",
        "        temp_cfg = config.temporal\n",
        "        self.apply_pre_emphasis = temp_cfg.get(\"emphasis\", True)\n",
        "        self.highpass_cutoff = temp_cfg.get(\"highpass_cutoff\", 30.0)\n",
        "        self.cqt_cfg = config.cepstral\n",
        "\n",
        "    def __call__(self, waveform: Tensor) -> MultiBranchFeatures:\n",
        "        waveform = ensure_mono(waveform)\n",
        "        mel = self._compute_mel_spectrogram(waveform)\n",
        "        temporal = self._prepare_temporal_branch(waveform)\n",
        "        cqt = self._compute_cqt(waveform)\n",
        "        return {\"spectral\": mel, \"temporal\": temporal, \"cepstral\": cqt}\n",
        "\n",
        "    def _compute_mel_spectrogram(self, waveform: Tensor) -> Tensor:\n",
        "        mel = self.mel_transform(waveform)\n",
        "        return torch.log1p(mel)\n",
        "\n",
        "    def _prepare_temporal_branch(self, waveform: Tensor) -> Tensor:\n",
        "        output = waveform\n",
        "        if self.apply_pre_emphasis:\n",
        "            output = torchaudio.functional.preemphasis(output, 0.97)\n",
        "        if self.highpass_cutoff is not None and self.highpass_cutoff > 0:\n",
        "            output = torchaudio.functional.highpass_biquad(\n",
        "                output,\n",
        "                sample_rate=self.config.sample_rate,\n",
        "                cutoff_freq=self.highpass_cutoff,\n",
        "            )\n",
        "        return output\n",
        "\n",
        "    def _compute_cqt(self, waveform: Tensor) -> Tensor:\n",
        "        y = waveform.squeeze(0).cpu().numpy()\n",
        "        cqt = librosa.cqt(\n",
        "            y,\n",
        "            sr=self.config.sample_rate,\n",
        "            hop_length=self.cqt_cfg.get(\"hop_length\", 256),\n",
        "            n_bins=self.cqt_cfg.get(\"n_bins\", 84),\n",
        "            bins_per_octave=self.cqt_cfg.get(\"bins_per_octave\", 12),\n",
        "            fmin=self.cqt_cfg.get(\"f_min\", 32.7),\n",
        "        )\n",
        "        magnitude = torch.from_numpy((np.abs(cqt) ** 2).astype(\"float32\"))\n",
        "        magnitude = torch.log1p(magnitude)\n",
        "        return magnitude.unsqueeze(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Dataset và DataModule\n",
        "Các cell tương ứng với `src/data/asvspoof_dataset.py` và `src/data/datamodule.py`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "LA_LABELS = {\"bonafide\": 0, \"spoof\": 1}\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ASVExample:\n",
        "    utt_id: str\n",
        "    speaker_id: str\n",
        "    path: str\n",
        "    label: int\n",
        "    system_id: Optional[str] = None\n",
        "    attack_type: Optional[str] = None\n",
        "\n",
        "\n",
        "class ASVspoofLADataset(Dataset):\n",
        "    \"\"\"Dataset PyTorch cho bộ ASVspoof2019 LA.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        data_root: str,\n",
        "        partition: str,\n",
        "        feature_extractor: MultiBranchFeatureExtractor,\n",
        "        protocol_file: Optional[str] = None,\n",
        "        sample_rate: int = 16000,\n",
        "        max_duration: float = 6.0,\n",
        "        pad_mode: str = \"repeat\",\n",
        "        preload_waveforms: bool = False,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.data_root = data_root\n",
        "        self.partition = partition\n",
        "        self.sample_rate = sample_rate\n",
        "        self.max_num_samples = int(sample_rate * max_duration)\n",
        "        self.pad_mode = pad_mode\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.preload_waveforms = preload_waveforms\n",
        "\n",
        "        if protocol_file is None:\n",
        "            proto_dir = os.path.join(\n",
        "                data_root,\n",
        "                f\"ASVspoof2019_LA_{partition}\",\n",
        "                \"protocol\",\n",
        "            )\n",
        "            pattern = f\"ASVspoof2019.LA.cm.{partition}.trn.txt\"\n",
        "            candidates = [\n",
        "                os.path.join(proto_dir, pattern),\n",
        "                os.path.join(proto_dir, pattern.replace(\".trn\", \"\")),\n",
        "            ]\n",
        "            exists = [path for path in candidates if os.path.exists(path)]\n",
        "            if not exists:\n",
        "                raise FileNotFoundError(\n",
        "                    f\"Không tìm thấy protocol cho partition={partition}. Checked: {candidates}\"\n",
        "                )\n",
        "            protocol_file = exists[0]\n",
        "\n",
        "        self.protocol_file = protocol_file\n",
        "        self.examples = self._load_metadata()\n",
        "\n",
        "        if self.preload_waveforms:\n",
        "            self._waveform_cache: Dict[str, Tensor] = {}\n",
        "            for example in self.examples:\n",
        "                waveform, _ = load_audio(example.path, self.sample_rate, normalize=True)\n",
        "                waveform = pad_or_trim(waveform, self.max_num_samples, mode=self.pad_mode)\n",
        "                self._waveform_cache[example.utt_id] = waveform\n",
        "        else:\n",
        "            self._waveform_cache = {}\n",
        "\n",
        "    def _load_metadata(self) -> List[ASVExample]:\n",
        "        examples: List[ASVExample] = []\n",
        "        with open(self.protocol_file, \"r\", encoding=\"utf-8\") as handle:\n",
        "            reader = csv.reader(handle, delimiter=\" \")\n",
        "            for row in reader:\n",
        "                tokens = [tok for tok in row if tok]\n",
        "                if not tokens:\n",
        "                    continue\n",
        "                if len(tokens) == 4:\n",
        "                    speaker_id, utt_id, system_id, label_token = tokens\n",
        "                    attack_type = None\n",
        "                elif len(tokens) >= 5:\n",
        "                    speaker_id, utt_id, system_id, attack_type, label_token = tokens[:5]\n",
        "                else:\n",
        "                    raise ValueError(f\"Không thể parse dòng protocol: {tokens}\")\n",
        "\n",
        "                label_token = label_token.lower()\n",
        "                if label_token not in LA_LABELS:\n",
        "                    raise ValueError(f\"Nhãn không hợp lệ: {label_token}\")\n",
        "\n",
        "                partition_dir = f\"ASVspoof2019_LA_{self.partition}\"\n",
        "                audio_dir = os.path.join(self.data_root, partition_dir, \"flac\")\n",
        "                audio_path = os.path.join(audio_dir, f\"{utt_id}.flac\")\n",
        "                if not os.path.exists(audio_path):\n",
        "                    wav_path = os.path.join(audio_dir, f\"{utt_id}.wav\")\n",
        "                    if os.path.exists(wav_path):\n",
        "                        audio_path = wav_path\n",
        "                    else:\n",
        "                        raise FileNotFoundError(\n",
        "                            f\"Không tìm thấy file audio cho {utt_id} tại {audio_dir}\"\n",
        "                        )\n",
        "\n",
        "                examples.append(\n",
        "                    ASVExample(\n",
        "                        utt_id=utt_id,\n",
        "                        speaker_id=speaker_id,\n",
        "                        path=audio_path,\n",
        "                        label=LA_LABELS[label_token],\n",
        "                        system_id=system_id,\n",
        "                        attack_type=attack_type,\n",
        "                    )\n",
        "                )\n",
        "        return examples\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, index: int) -> Dict[str, Tensor]:\n",
        "        example = self.examples[index]\n",
        "        if example.utt_id in self._waveform_cache:\n",
        "            waveform = self._waveform_cache[example.utt_id]\n",
        "        else:\n",
        "            waveform, _ = load_audio(example.path, self.sample_rate, normalize=True)\n",
        "            waveform = pad_or_trim(waveform, self.max_num_samples, mode=self.pad_mode)\n",
        "\n",
        "        features = self.feature_extractor(waveform)\n",
        "        sample: Dict[str, Any] = {\n",
        "            \"utt_id\": example.utt_id,\n",
        "            \"speaker_id\": example.speaker_id,\n",
        "            \"label\": torch.tensor(example.label, dtype=torch.long),\n",
        "            \"features\": features,\n",
        "        }\n",
        "\n",
        "        metadata = {}\n",
        "        if example.system_id is not None:\n",
        "            metadata[\"system_id\"] = example.system_id\n",
        "        if example.attack_type is not None:\n",
        "            metadata[\"attack_type\"] = example.attack_type\n",
        "        if metadata:\n",
        "            sample[\"meta\"] = metadata\n",
        "        return sample\n",
        "\n",
        "\n",
        "def collate_fn(batch: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
        "    \"\"\"Ghép batch và giữ các nhánh đặc trưng ở dạng riêng biệt.\"\"\"\n",
        "    labels = torch.stack([item[\"label\"] for item in batch], dim=0)\n",
        "\n",
        "    branch_tensors: Dict[str, List[Tensor]] = {}\n",
        "    for item in batch:\n",
        "        features: MultiBranchFeatures = item[\"features\"]\n",
        "        for branch_name, tensor in features.items():\n",
        "            branch_tensors.setdefault(branch_name, []).append(tensor)\n",
        "\n",
        "    stacked_features = {\n",
        "        branch_name: torch.stack(tensors, dim=0)\n",
        "        for branch_name, tensors in branch_tensors.items()\n",
        "    }\n",
        "\n",
        "    output: Dict[str, Any] = {\n",
        "        \"features\": stacked_features,\n",
        "        \"labels\": labels,\n",
        "        \"utt_ids\": [item[\"utt_id\"] for item in batch],\n",
        "        \"speaker_ids\": [item[\"speaker_id\"] for item in batch],\n",
        "    }\n",
        "\n",
        "    metas = [item.get(\"meta\") for item in batch]\n",
        "    if any(meta is not None for meta in metas):\n",
        "        output[\"meta\"] = metas\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class PartitionConfig:\n",
        "    partition: str\n",
        "    protocol_file: Optional[str] = None\n",
        "    batch_size: int = 32\n",
        "    shuffle: bool = True\n",
        "    drop_last: bool = False\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DataModuleConfig:\n",
        "    data_root: str\n",
        "    sample_rate: int = 16000\n",
        "    max_duration: float = 6.0\n",
        "    pad_mode: str = \"repeat\"\n",
        "    num_workers: int = 4\n",
        "    pin_memory: bool = True\n",
        "    prefetch_factor: int = 2\n",
        "    feature: FeatureConfig = field(default_factory=FeatureConfig)\n",
        "    train: Optional[PartitionConfig] = None\n",
        "    valid: Optional[PartitionConfig] = None\n",
        "    test: Optional[PartitionConfig] = None\n",
        "    preload_waveforms: bool = False\n",
        "\n",
        "\n",
        "class ASVspoofDataModule:\n",
        "    \"\"\"Đóng gói logic tạo DataLoader cho train / validation / test.\"\"\"\n",
        "\n",
        "    def __init__(self, config: DataModuleConfig) -> None:\n",
        "        if config.train is None or config.valid is None:\n",
        "            raise ValueError(\"Cần cấu hình train và valid partitions.\")\n",
        "        self.config = config\n",
        "        self.feature_extractor = MultiBranchFeatureExtractor(config.feature)\n",
        "        self._datasets: Dict[str, ASVspoofLADataset] = {}\n",
        "\n",
        "    def setup(self, stage: Optional[str] = None) -> None:\n",
        "        if stage in (None, \"fit\"):\n",
        "            self._datasets[\"train\"] = self._build_dataset(self.config.train)\n",
        "            self._datasets[\"valid\"] = self._build_dataset(self.config.valid)\n",
        "        if stage in (None, \"test\") and self.config.test is not None:\n",
        "            self._datasets[\"test\"] = self._build_dataset(self.config.test)\n",
        "\n",
        "    def _build_dataset(self, part_cfg: PartitionConfig) -> ASVspoofLADataset:\n",
        "        return ASVspoofLADataset(\n",
        "            data_root=self.config.data_root,\n",
        "            partition=part_cfg.partition,\n",
        "            protocol_file=part_cfg.protocol_file,\n",
        "            feature_extractor=self.feature_extractor,\n",
        "            sample_rate=self.config.sample_rate,\n",
        "            max_duration=self.config.max_duration,\n",
        "            pad_mode=self.config.pad_mode,\n",
        "            preload_waveforms=self.config.preload_waveforms,\n",
        "        )\n",
        "\n",
        "    def _build_loader(self, dataset: ASVspoofLADataset, part_cfg: PartitionConfig) -> DataLoader:\n",
        "        loader_kwargs = dict(\n",
        "            dataset=dataset,\n",
        "            batch_size=part_cfg.batch_size,\n",
        "            shuffle=part_cfg.shuffle,\n",
        "            drop_last=part_cfg.drop_last,\n",
        "            num_workers=self.config.num_workers,\n",
        "            pin_memory=self.config.pin_memory,\n",
        "            collate_fn=collate_fn,\n",
        "        )\n",
        "        if self.config.num_workers > 0:\n",
        "            loader_kwargs[\"prefetch_factor\"] = self.config.prefetch_factor\n",
        "        return DataLoader(**loader_kwargs)\n",
        "\n",
        "    def train_dataloader(self) -> DataLoader:\n",
        "        return self._build_loader(self._datasets[\"train\"], self.config.train)\n",
        "\n",
        "    def val_dataloader(self) -> DataLoader:\n",
        "        return self._build_loader(self._datasets[\"valid\"], self.config.valid)\n",
        "\n",
        "    def test_dataloader(self) -> DataLoader:\n",
        "        if \"test\" not in self._datasets:\n",
        "            raise RuntimeError(\"Chưa cấu hình test dataset.\")\n",
        "        assert self.config.test is not None\n",
        "        return self._build_loader(self._datasets[\"test\"], self.config.test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Kiến trúc mô hình đa nhánh\n",
        "Các cell này tương ứng với `src/models/multi_branch_model.py`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def conv2d_block(\n",
        "    in_channels: int,\n",
        "    out_channels: int,\n",
        "    kernel_size: Tuple[int, int] = (3, 3),\n",
        "    stride: Tuple[int, int] = (1, 1),\n",
        "    padding: Tuple[int, int] = (1, 1),\n",
        "    dropout: float = 0.0,\n",
        ") -> nn.Sequential:\n",
        "    layers = [\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "    ]\n",
        "    if dropout > 0:\n",
        "        layers.append(nn.Dropout2d(dropout))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def conv1d_block(\n",
        "    in_channels: int,\n",
        "    out_channels: int,\n",
        "    kernel_size: int = 3,\n",
        "    stride: int = 1,\n",
        "    padding: int = 1,\n",
        "    dropout: float = 0.0,\n",
        ") -> nn.Sequential:\n",
        "    layers = [\n",
        "        nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding),\n",
        "        nn.BatchNorm1d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "    ]\n",
        "    if dropout > 0:\n",
        "        layers.append(nn.Dropout(dropout))\n",
        "    return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class SpectralBranch(nn.Module):\n",
        "    def __init__(self, in_channels: int = 1, hidden_dim: int = 256) -> None:\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            conv2d_block(in_channels, 32, dropout=0.1),\n",
        "            nn.MaxPool2d((2, 2)),\n",
        "            conv2d_block(32, 64, dropout=0.15),\n",
        "            nn.MaxPool2d((2, 2)),\n",
        "            conv2d_block(64, 128, dropout=0.2),\n",
        "            conv2d_block(128, 128, dropout=0.2),\n",
        "        )\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128, hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.features(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.proj(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class TemporalBranch(nn.Module):\n",
        "    def __init__(self, in_channels: int = 1, hidden_dim: int = 256) -> None:\n",
        "        super().__init__()\n",
        "        self.conv_stack = nn.Sequential(\n",
        "            conv1d_block(in_channels, 32, kernel_size=11, stride=2, padding=5, dropout=0.1),\n",
        "            conv1d_block(32, 64, kernel_size=9, stride=2, padding=4, dropout=0.1),\n",
        "            conv1d_block(64, 128, kernel_size=7, stride=2, padding=3, dropout=0.15),\n",
        "            conv1d_block(128, 128, kernel_size=5, stride=1, padding=2, dropout=0.15),\n",
        "        )\n",
        "        self.temporal_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128, hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.conv_stack(x)\n",
        "        x = self.temporal_pool(x)\n",
        "        x = self.proj(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class CepstralBranch(nn.Module):\n",
        "    def __init__(self, in_channels: int = 1, hidden_dim: int = 256) -> None:\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            conv2d_block(in_channels, 32, kernel_size=(3, 5), padding=(1, 2), dropout=0.1),\n",
        "            nn.MaxPool2d((2, 2)),\n",
        "            conv2d_block(32, 64, kernel_size=(3, 5), padding=(1, 2), dropout=0.15),\n",
        "            nn.MaxPool2d((2, 2)),\n",
        "            conv2d_block(64, 128, kernel_size=(3, 3), padding=(1, 1), dropout=0.2),\n",
        "        )\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128, hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.features(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.proj(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class AttentionFusion(nn.Module):\n",
        "    \"\"\"Tầng self-attention đơn giản trên embedding của các nhánh.\"\"\"\n",
        "\n",
        "    def __init__(self, embed_dim: int, attn_dim: int = 128, dropout: float = 0.1) -> None:\n",
        "        super().__init__()\n",
        "        self.proj = nn.Linear(embed_dim, attn_dim)\n",
        "        self.score = nn.Linear(attn_dim, 1, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, branch_embeddings: Tensor) -> Tuple[Tensor, Tensor]:\n",
        "        attn_hidden = torch.tanh(self.proj(branch_embeddings))\n",
        "        scores = self.score(attn_hidden).squeeze(-1)\n",
        "        weights = torch.softmax(scores, dim=-1)\n",
        "        branch_embeddings = self.dropout(branch_embeddings)\n",
        "        fused = torch.sum(branch_embeddings * weights.unsqueeze(-1), dim=1)\n",
        "        return fused, weights\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class MultiBranchModelConfig:\n",
        "    embed_dim: int = 256\n",
        "    attn_dim: int = 128\n",
        "    num_classes: int = 2\n",
        "    classifier_hidden: int = 128\n",
        "    dropout: float = 0.3\n",
        "\n",
        "\n",
        "class MultiBranchAttentionModel(nn.Module):\n",
        "    \"\"\"Kiến trúc đa nhánh với attention fusion.\"\"\"\n",
        "\n",
        "    def __init__(self, config: MultiBranchModelConfig) -> None:\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.branches = nn.ModuleDict(\n",
        "            {\n",
        "                \"spectral\": SpectralBranch(in_channels=1, hidden_dim=config.embed_dim),\n",
        "                \"temporal\": TemporalBranch(in_channels=1, hidden_dim=config.embed_dim),\n",
        "                \"cepstral\": CepstralBranch(in_channels=1, hidden_dim=config.embed_dim),\n",
        "            }\n",
        "        )\n",
        "        self.fusion = AttentionFusion(config.embed_dim, config.attn_dim, dropout=config.dropout)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(config.embed_dim, config.classifier_hidden),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(config.dropout),\n",
        "            nn.Linear(config.classifier_hidden, config.num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, features: Dict[str, Tensor]) -> Dict[str, Tensor]:\n",
        "        branch_outputs = []\n",
        "        attn_order = []\n",
        "        for branch_name, module in self.branches.items():\n",
        "            if branch_name not in features:\n",
        "                raise KeyError(f\"Thiếu nhánh {branch_name} trong input features.\")\n",
        "            branch_out = module(features[branch_name])\n",
        "            branch_outputs.append(branch_out.unsqueeze(1))\n",
        "            attn_order.append(branch_name)\n",
        "\n",
        "        branch_stack = torch.cat(branch_outputs, dim=1)\n",
        "        fused, weights = self.fusion(branch_stack)\n",
        "        logits = self.classifier(fused)\n",
        "        return {\n",
        "            \"logits\": logits,\n",
        "            \"fused\": fused,\n",
        "            \"attention_weights\": weights,\n",
        "            \"branch_embeddings\": branch_stack,\n",
        "            \"branch_order\": attn_order,\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Hàm đánh giá và metric\n",
        "Tương ứng với `src/utils/metrics.py`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def compute_accuracy(logits: Tensor, labels: Tensor) -> float:\n",
        "    preds = torch.argmax(logits, dim=1)\n",
        "    correct = (preds == labels).sum().item()\n",
        "    return correct / labels.numel()\n",
        "\n",
        "\n",
        "def compute_eer(scores: Tensor, labels: Tensor) -> float:\n",
        "    \"\"\"Tính Equal Error Rate (EER).\"\"\"\n",
        "    labels_np = labels.detach().cpu().numpy().astype(np.int32)\n",
        "    scores_np = scores.detach().cpu().numpy()\n",
        "\n",
        "    order = np.argsort(scores_np)[::-1]\n",
        "    sorted_labels = labels_np[order]\n",
        "\n",
        "    positives = sorted_labels.sum()\n",
        "    negatives = len(sorted_labels) - positives\n",
        "    if positives == 0 or negatives == 0:\n",
        "        return 0.0\n",
        "\n",
        "    false_accepts = 0\n",
        "    false_rejects = positives\n",
        "    min_gap = 1.0\n",
        "    eer = 1.0\n",
        "\n",
        "    for label in sorted_labels:\n",
        "        if label == 1:\n",
        "            false_rejects -= 1\n",
        "        else:\n",
        "            false_accepts += 1\n",
        "\n",
        "        far = false_accepts / negatives\n",
        "        frr = false_rejects / positives\n",
        "        gap = abs(far - frr)\n",
        "        if gap < min_gap:\n",
        "            min_gap = gap\n",
        "            eer = (far + frr) / 2.0\n",
        "    return float(eer)\n",
        "\n",
        "\n",
        "def aggregate_metrics(logits: Tensor, labels: Tensor) -> Dict[str, float]:\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    spoof_scores = probs[:, 1]\n",
        "    accuracy = compute_accuracy(logits, labels)\n",
        "    eer = compute_eer(spoof_scores, labels)\n",
        "    return {\"accuracy\": accuracy, \"eer\": eer}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Vòng lặp huấn luyện\n",
        "Các cell dưới đây tương ứng với `src/training/engine.py`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class OptimizerConfig:\n",
        "    lr: float = 1e-4\n",
        "    weight_decay: float = 1e-5\n",
        "    betas: tuple = (0.9, 0.98)\n",
        "    eps: float = 1e-8\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class SchedulerConfig:\n",
        "    use_cosine: bool = True\n",
        "    min_lr: float = 1e-6\n",
        "    t_max: Optional[int] = None\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class TrainingConfig:\n",
        "    epochs: int = 50\n",
        "    device: Optional[str] = None\n",
        "    log_interval: int = 20\n",
        "    grad_clip: float = 5.0\n",
        "    mixed_precision: bool = True\n",
        "    checkpoint_dir: str = \"checkpoints\"\n",
        "    best_metric: str = \"eer\"\n",
        "    patience: int = 10\n",
        "    resume_from: Optional[str] = None\n",
        "    save_every: int = 0\n",
        "    history: List[Dict[str, float]] = field(default_factory=list)\n",
        "    evaluate_on_test: bool = False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: nn.Module,\n",
        "        train_config: TrainingConfig,\n",
        "        optim_config: OptimizerConfig,\n",
        "        scheduler_config: SchedulerConfig,\n",
        "    ) -> None:\n",
        "        self.model = model\n",
        "        self.train_config = train_config\n",
        "        self.optim_config = optim_config\n",
        "        self.scheduler_config = scheduler_config\n",
        "\n",
        "        device_str = (\n",
        "            train_config.device\n",
        "            if train_config.device is not None\n",
        "            else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        )\n",
        "        self.device = torch.device(device_str)\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.scaler = torch.cuda.amp.GradScaler(\n",
        "            enabled=(self.device.type == \"cuda\" and train_config.mixed_precision)\n",
        "        )\n",
        "        self.best_metric_value: Optional[float] = None\n",
        "        self.best_epoch: Optional[int] = None\n",
        "\n",
        "    def fit(self, datamodule: ASVspoofDataModule) -> Dict[str, List[Dict[str, float]]]:\n",
        "        datamodule.setup(stage=\"fit\")\n",
        "        train_loader = datamodule.train_dataloader()\n",
        "        valid_loader = datamodule.val_dataloader()\n",
        "\n",
        "        optimizer = torch.optim.AdamW(\n",
        "            self.model.parameters(),\n",
        "            lr=self.optim_config.lr,\n",
        "            weight_decay=self.optim_config.weight_decay,\n",
        "            betas=self.optim_config.betas,\n",
        "            eps=self.optim_config.eps,\n",
        "        )\n",
        "        scheduler = self._build_scheduler(optimizer)\n",
        "        os.makedirs(self.train_config.checkpoint_dir, exist_ok=True)\n",
        "\n",
        "        history = {\"train\": [], \"valid\": []}\n",
        "        patience_counter = 0\n",
        "\n",
        "        for epoch in range(1, self.train_config.epochs + 1):\n",
        "            train_metrics = self._run_epoch(\n",
        "                loader=train_loader,\n",
        "                optimizer=optimizer,\n",
        "                scheduler=scheduler,\n",
        "                epoch=epoch,\n",
        "                train=True,\n",
        "            )\n",
        "            valid_metrics = self._run_epoch(\n",
        "                loader=valid_loader,\n",
        "                optimizer=None,\n",
        "                scheduler=None,\n",
        "                epoch=epoch,\n",
        "                train=False,\n",
        "            )\n",
        "\n",
        "            history[\"train\"].append(train_metrics)\n",
        "            history[\"valid\"].append(valid_metrics)\n",
        "            self.train_config.history.append(\n",
        "                {\"epoch\": epoch, **train_metrics, **{f\"val_{k}\": v for k, v in valid_metrics.items()}}\n",
        "            )\n",
        "\n",
        "            current_metric = valid_metrics.get(self.train_config.best_metric)\n",
        "            if current_metric is None:\n",
        "                raise KeyError(\n",
        "                    f\"Không tìm thấy metric {self.train_config.best_metric} trong valid metrics: {valid_metrics}\"\n",
        "                )\n",
        "\n",
        "            if self._is_better(current_metric):\n",
        "                self.best_metric_value = current_metric\n",
        "                self.best_epoch = epoch\n",
        "                patience_counter = 0\n",
        "                self._save_checkpoint(optimizer, epoch, best=True)\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            if self.train_config.save_every > 0 and epoch % self.train_config.save_every == 0:\n",
        "                self._save_checkpoint(optimizer, epoch, best=False)\n",
        "\n",
        "            if scheduler is not None and getattr(scheduler, \"step\", None) is not None:\n",
        "                scheduler.step()\n",
        "\n",
        "            if patience_counter >= self.train_config.patience:\n",
        "                print(f\"[Trainer] Early stopping ở epoch {epoch}.\")\n",
        "                break\n",
        "\n",
        "        return history\n",
        "\n",
        "    def evaluate(self, datamodule: ASVspoofDataModule) -> Dict[str, float]:\n",
        "        datamodule.setup(stage=\"test\")\n",
        "        test_loader = datamodule.test_dataloader()\n",
        "        metrics = self._run_epoch(loader=test_loader, optimizer=None, scheduler=None, epoch=0, train=False)\n",
        "        return metrics\n",
        "\n",
        "    def _run_epoch(\n",
        "        self,\n",
        "        loader: DataLoader,\n",
        "        optimizer: Optional[torch.optim.Optimizer],\n",
        "        scheduler: Optional[torch.optim.lr_scheduler._LRScheduler],\n",
        "        epoch: int,\n",
        "        train: bool,\n",
        "    ) -> Dict[str, float]:\n",
        "        if train:\n",
        "            self.model.train()\n",
        "        else:\n",
        "            self.model.eval()\n",
        "\n",
        "        total_loss = 0.0\n",
        "        total_samples = 0\n",
        "        all_logits: List[Tensor] = []\n",
        "        all_labels: List[Tensor] = []\n",
        "\n",
        "        for step, batch in enumerate(loader, start=1):\n",
        "            features = {\n",
        "                name: tensor.to(self.device, non_blocking=True)\n",
        "                for name, tensor in batch[\"features\"].items()\n",
        "            }\n",
        "            labels = batch[\"labels\"].to(self.device, non_blocking=True)\n",
        "            batch_size = labels.size(0)\n",
        "\n",
        "            with torch.set_grad_enabled(train):\n",
        "                with torch.cuda.amp.autocast(enabled=self.scaler.is_enabled()):\n",
        "                    outputs = self.model(features)\n",
        "                    logits = outputs[\"logits\"]\n",
        "                    loss = self.criterion(logits, labels)\n",
        "\n",
        "                if train:\n",
        "                    assert optimizer is not None\n",
        "                    self.scaler.scale(loss).backward()\n",
        "                    if self.train_config.grad_clip > 0:\n",
        "                        self.scaler.unscale_(optimizer)\n",
        "                        torch.nn.utils.clip_grad_norm_(\n",
        "                            self.model.parameters(), self.train_config.grad_clip\n",
        "                        )\n",
        "                    self.scaler.step(optimizer)\n",
        "                    self.scaler.update()\n",
        "                    optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            total_loss += loss.item() * batch_size\n",
        "            total_samples += batch_size\n",
        "            all_logits.append(logits.detach().cpu())\n",
        "            all_labels.append(labels.detach().cpu())\n",
        "\n",
        "            if train and self.train_config.log_interval and step % self.train_config.log_interval == 0:\n",
        "                current_loss = total_loss / total_samples\n",
        "                lr = optimizer.param_groups[0]['lr'] if optimizer is not None else 0.0\n",
        "                print(\n",
        "                    f\"[Epoch {epoch}] Step {step}/{len(loader)} \"\n",
        "                    f\"Loss: {current_loss:.4f} LR: {lr:.2e}\"\n",
        "                )\n",
        "\n",
        "        avg_loss = total_loss / max(total_samples, 1)\n",
        "        logits_tensor = torch.cat(all_logits, dim=0)\n",
        "        labels_tensor = torch.cat(all_labels, dim=0)\n",
        "        metrics = aggregate_metrics(logits_tensor, labels_tensor)\n",
        "        metrics[\"loss\"] = avg_loss\n",
        "        return metrics\n",
        "\n",
        "    def _is_better(self, value: float) -> bool:\n",
        "        if self.best_metric_value is None:\n",
        "            return True\n",
        "        if self.train_config.best_metric in {\"loss\", \"eer\"}:\n",
        "            return value < self.best_metric_value\n",
        "        return value > self.best_metric_value\n",
        "\n",
        "    def _save_checkpoint(self, optimizer: Optional[torch.optim.Optimizer], epoch: int, best: bool) -> None:\n",
        "        state = {\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state_dict\": self.model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict() if optimizer is not None else None,\n",
        "            \"best_metric\": self.best_metric_value,\n",
        "            \"best_epoch\": self.best_epoch,\n",
        "        }\n",
        "        suffix = \"best\" if best else f\"epoch_{epoch:03d}\"\n",
        "        path = os.path.join(self.train_config.checkpoint_dir, f\"checkpoint_{suffix}.pt\")\n",
        "        torch.save(state, path)\n",
        "        tag = \"BEST\" if best else \"SNAPSHOT\"\n",
        "        print(f\"[Trainer] Đã lưu checkpoint ({tag}) tại {path}\")\n",
        "\n",
        "    def _build_scheduler(self, optimizer: torch.optim.Optimizer):\n",
        "        if not self.scheduler_config.use_cosine:\n",
        "            return None\n",
        "        t_max = (\n",
        "            self.scheduler_config.t_max\n",
        "            if self.scheduler_config.t_max is not None\n",
        "            else self.train_config.epochs\n",
        "        )\n",
        "        return torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "            optimizer,\n",
        "            T_max=t_max,\n",
        "            eta_min=self.scheduler_config.min_lr,\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Hàm tiện ích đọc YAML và xây cấu hình\n",
        "Phần này tương đương `train.py` trong dự án gốc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def load_yaml_config(path: str) -> Dict[str, Any]:\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as handle:\n",
        "        return yaml.safe_load(handle)\n",
        "\n",
        "\n",
        "def build_feature_config(cfg: Dict[str, Any]) -> FeatureConfig:\n",
        "    base = FeatureConfig()\n",
        "    spectral = {**base.spectral, **cfg.get(\"spectral\", {})}\n",
        "    temporal = {**base.temporal, **cfg.get(\"temporal\", {})}\n",
        "    cepstral = {**base.cepstral, **cfg.get(\"cepstral\", {})}\n",
        "    return FeatureConfig(\n",
        "        sample_rate=cfg.get(\"sample_rate\", base.sample_rate),\n",
        "        spectral=spectral,\n",
        "        temporal=temporal,\n",
        "        cepstral=cepstral,\n",
        "    )\n",
        "\n",
        "\n",
        "def build_partition_config(cfg: Dict[str, Any]) -> PartitionConfig:\n",
        "    return PartitionConfig(\n",
        "        partition=cfg[\"partition\"],\n",
        "        protocol_file=cfg.get(\"protocol_file\"),\n",
        "        batch_size=cfg.get(\"batch_size\", 32),\n",
        "        shuffle=cfg.get(\"shuffle\", True),\n",
        "        drop_last=cfg.get(\"drop_last\", False),\n",
        "    )\n",
        "\n",
        "\n",
        "def build_data_module_config(cfg: Dict[str, Any]) -> DataModuleConfig:\n",
        "    feature_cfg = build_feature_config(cfg.get(\"feature\", {}))\n",
        "    train_cfg = build_partition_config(cfg[\"train\"])\n",
        "    valid_cfg = build_partition_config(cfg[\"valid\"])\n",
        "    test_cfg = (\n",
        "        build_partition_config(cfg[\"test\"]) if cfg.get(\"test\") is not None else None\n",
        "    )\n",
        "    return DataModuleConfig(\n",
        "        data_root=cfg[\"data_root\"],\n",
        "        sample_rate=cfg.get(\"sample_rate\", feature_cfg.sample_rate),\n",
        "        max_duration=cfg.get(\"max_duration\", 6.0),\n",
        "        pad_mode=cfg.get(\"pad_mode\", \"repeat\"),\n",
        "        num_workers=cfg.get(\"num_workers\", 4),\n",
        "        pin_memory=cfg.get(\"pin_memory\", True),\n",
        "        prefetch_factor=cfg.get(\"prefetch_factor\", 2),\n",
        "        feature=feature_cfg,\n",
        "        train=train_cfg,\n",
        "        valid=valid_cfg,\n",
        "        test=test_cfg,\n",
        "        preload_waveforms=cfg.get(\"preload_waveforms\", False),\n",
        "    )\n",
        "\n",
        "\n",
        "def build_model_config(cfg: Dict[str, Any]) -> MultiBranchModelConfig:\n",
        "    base = MultiBranchModelConfig()\n",
        "    return MultiBranchModelConfig(\n",
        "        embed_dim=cfg.get(\"embed_dim\", base.embed_dim),\n",
        "        attn_dim=cfg.get(\"attn_dim\", base.attn_dim),\n",
        "        num_classes=cfg.get(\"num_classes\", base.num_classes),\n",
        "        classifier_hidden=cfg.get(\"classifier_hidden\", base.classifier_hidden),\n",
        "        dropout=cfg.get(\"dropout\", base.dropout),\n",
        "    )\n",
        "\n",
        "\n",
        "def build_training_config(cfg: Dict[str, Any]) -> TrainingConfig:\n",
        "    base = TrainingConfig()\n",
        "    return TrainingConfig(\n",
        "        epochs=cfg.get(\"epochs\", base.epochs),\n",
        "        device=cfg.get(\"device\", base.device),\n",
        "        log_interval=cfg.get(\"log_interval\", base.log_interval),\n",
        "        grad_clip=cfg.get(\"grad_clip\", base.grad_clip),\n",
        "        mixed_precision=cfg.get(\"mixed_precision\", base.mixed_precision),\n",
        "        checkpoint_dir=cfg.get(\"checkpoint_dir\", base.checkpoint_dir),\n",
        "        best_metric=cfg.get(\"best_metric\", base.best_metric),\n",
        "        patience=cfg.get(\"patience\", base.patience),\n",
        "        resume_from=cfg.get(\"resume_from\", base.resume_from),\n",
        "        save_every=cfg.get(\"save_every\", base.save_every),\n",
        "        history=cfg.get(\"history\", base.history),\n",
        "        evaluate_on_test=cfg.get(\"evaluate_on_test\", base.evaluate_on_test),\n",
        "    )\n",
        "\n",
        "\n",
        "def build_optimizer_config(cfg: Dict[str, Any]) -> OptimizerConfig:\n",
        "    base = OptimizerConfig()\n",
        "    return OptimizerConfig(\n",
        "        lr=cfg.get(\"lr\", base.lr),\n",
        "        weight_decay=cfg.get(\"weight_decay\", base.weight_decay),\n",
        "        betas=tuple(cfg.get(\"betas\", base.betas)),\n",
        "        eps=cfg.get(\"eps\", base.eps),\n",
        "    )\n",
        "\n",
        "\n",
        "def build_scheduler_config(cfg: Dict[str, Any], total_epochs: int) -> SchedulerConfig:\n",
        "    base = SchedulerConfig()\n",
        "    use_cosine = cfg.get(\"use_cosine\", base.use_cosine)\n",
        "    min_lr = cfg.get(\"min_lr\", base.min_lr)\n",
        "    t_max = cfg.get(\"t_max\", total_epochs if base.t_max is None else base.t_max)\n",
        "    return SchedulerConfig(use_cosine=use_cosine, min_lr=min_lr, t_max=t_max)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Hàm chạy huấn luyện chính\n",
        "Cell này gom tất cả lại tương đương hàm `main()` trong `train.py`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def run_training_from_config(config: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    data_cfg = build_data_module_config(config[\"data\"])\n",
        "    model_cfg = build_model_config(config.get(\"model\", {}))\n",
        "    training_cfg = build_training_config(config.get(\"training\", {}))\n",
        "    optimizer_cfg = build_optimizer_config(config.get(\"optimizer\", {}))\n",
        "    scheduler_cfg = build_scheduler_config(\n",
        "        config.get(\"scheduler\", {}),\n",
        "        total_epochs=training_cfg.epochs,\n",
        "    )\n",
        "\n",
        "    datamodule = ASVspoofDataModule(data_cfg)\n",
        "    model = MultiBranchAttentionModel(model_cfg)\n",
        "    trainer = Trainer(model, training_cfg, optimizer_cfg, scheduler_cfg)\n",
        "\n",
        "    history = trainer.fit(datamodule)\n",
        "    results = {\n",
        "        \"history\": history,\n",
        "        \"best_metric\": trainer.best_metric_value,\n",
        "        \"best_epoch\": trainer.best_epoch,\n",
        "    }\n",
        "\n",
        "    if training_cfg.evaluate_on_test and data_cfg.test is not None:\n",
        "        test_metrics = trainer.evaluate(datamodule)\n",
        "        results[\"test_metrics\"] = test_metrics\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Ví dụ cấu hình\n",
        "Bạn có thể chỉnh sửa trực tiếp dictionary bên dưới hoặc đọc YAML bằng `load_yaml_config`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "example_config = yaml.safe_load(\"\"\"data:\n",
        "  data_root: \"/kaggle/input/ASVspoof2019_LA\"\n",
        "  sample_rate: 16000\n",
        "  max_duration: 6.0\n",
        "  pad_mode: \"repeat\"\n",
        "  num_workers: 4\n",
        "  pin_memory: true\n",
        "  prefetch_factor: 2\n",
        "  preload_waveforms: false\n",
        "  feature:\n",
        "    spectral:\n",
        "      n_mels: 128\n",
        "      n_fft: 1024\n",
        "      hop_length: 256\n",
        "    temporal:\n",
        "      emphasis: true\n",
        "      highpass_cutoff: 20.0\n",
        "    cepstral:\n",
        "      n_bins: 96\n",
        "      bins_per_octave: 12\n",
        "  train:\n",
        "    partition: \"train\"\n",
        "    batch_size: 16\n",
        "    shuffle: true\n",
        "    drop_last: true\n",
        "  valid:\n",
        "    partition: \"dev\"\n",
        "    batch_size: 16\n",
        "    shuffle: false\n",
        "    drop_last: false\n",
        "  test: null\n",
        "model:\n",
        "  embed_dim: 256\n",
        "  attn_dim: 128\n",
        "  classifier_hidden: 128\n",
        "  dropout: 0.3\n",
        "training:\n",
        "  epochs: 50\n",
        "  device: null\n",
        "  log_interval: 20\n",
        "  grad_clip: 5.0\n",
        "  mixed_precision: true\n",
        "  checkpoint_dir: \"checkpoints\"\n",
        "  best_metric: \"eer\"\n",
        "  patience: 8\n",
        "  save_every: 0\n",
        "  evaluate_on_test: false\n",
        "optimizer:\n",
        "  lr: 0.0002\n",
        "  weight_decay: 0.00001\n",
        "  betas: [0.9, 0.98]\n",
        "scheduler:\n",
        "  use_cosine: true\n",
        "  min_lr: 0.000001\n",
        "\"\"\")\n",
        "example_config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Thực thi huấn luyện (tùy chọn)\n",
        "Chỉ chạy cell này khi bạn đã mount đúng dữ liệu. Nếu muốn đọc từ file YAML, dùng `config = load_yaml_config(path)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Ví dụ:\n",
        "# config = load_yaml_config(\"/kaggle/input/asvspoof-configs/asvspoof_multibranch.yaml\")\n",
        "# results = run_training_from_config(config)\n",
        "# results"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}