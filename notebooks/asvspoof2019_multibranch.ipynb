{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ASVspoof2019 LA Multi-Branch Training Notebook\n",
        "\n",
        "Notebook này chuyển toàn bộ pipeline huấn luyện mô hình đa nhánh sang định dạng dễ chạy trên Kaggle. Các cell dưới đây gom lại toàn bộ logic từ project gốc với các chú thích chi tiết để bạn dễ tuỳ biến."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Thiết lập môi trường\n",
        "Chạy cell dưới đây nếu bạn đang ở môi trường Kaggle và cần cài đặt phụ thuộc. Các gói trùng với bản `requirements.txt` gốc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Nếu chạy trên Kaggle Notebook bạn có thể bỏ comment dòng dưới để cài đặt phụ thuộc\n",
        "# !pip install -q -r /kaggle/input/your-requirements/requirements.txt\n",
        "# Hoặc khai báo thủ công:\n",
        "# !pip install -q torch torchaudio librosa pyyaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Import thư viện\n",
        "Tập hợp toàn bộ import cần thiết cho pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import csv\n",
        "import math\n",
        "import os\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchaudio\n",
        "import yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Cấu hình đặc trưng và helper xử lý audio\n",
        "Các hàm tiện ích gộp từ `src/utils/audio.py` và cấu hình đặc trưng ở `src/data/features.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_audio(path: str, target_sample_rate: int, normalize: bool = True) -> Tuple[Tensor, int]:\n",
        "    # Load audio, resample nếu cần và chuẩn hoá biên độ để phù hợp pipeline\n",
        "    waveform, sample_rate = torchaudio.load(path)\n",
        "    if sample_rate != target_sample_rate:\n",
        "        resampler = torchaudio.transforms.Resample(sample_rate, target_sample_rate)\n",
        "        waveform = resampler(waveform)\n",
        "        sample_rate = target_sample_rate\n",
        "    waveform = ensure_mono(waveform)\n",
        "    if normalize:\n",
        "        peak = waveform.abs().max()\n",
        "        if peak > 0:\n",
        "            waveform = waveform / peak\n",
        "    return waveform, sample_rate\n",
        "\n",
        "\n",
        "def ensure_mono(waveform: Tensor) -> Tensor:\n",
        "    # Đảm bảo waveform là mono (1 kênh) bằng cách trung bình các kênh\n",
        "    if waveform.size(0) == 1:\n",
        "        return waveform\n",
        "    return waveform.mean(dim=0, keepdim=True)\n",
        "\n",
        "\n",
        "def pad_or_trim(waveform: Tensor, target_num_samples: int, mode: str = \"repeat\") -> Tensor:\n",
        "    # Đưa waveform về độ dài cố định bằng cách cắt hoặc padding\n",
        "    current = waveform.size(-1)\n",
        "    if current == target_num_samples:\n",
        "        return waveform\n",
        "    if current > target_num_samples:\n",
        "        return waveform[..., :target_num_samples]\n",
        "\n",
        "    diff = target_num_samples - current\n",
        "    if mode == \"zeros\":\n",
        "        padded = torch.nn.functional.pad(waveform, (0, diff))\n",
        "    elif mode == \"reflect\":\n",
        "        padded = torch.nn.functional.pad(waveform, (0, diff), mode=\"reflect\")\n",
        "    elif mode == \"repeat\":\n",
        "        repeats = math.ceil(target_num_samples / current)\n",
        "        padded = waveform.repeat(1, repeats)[..., :target_num_samples]\n",
        "    else:\n",
        "        raise ValueError(f\"pad_mode không được hỗ trợ: {mode}\")\n",
        "\n",
        "    return padded\n",
        "\n",
        "\n",
        "class SpectralConfig(dict):\n",
        "    # Lưu thông số mel-spectrogram\n",
        "    pass\n",
        "\n",
        "\n",
        "class TemporalConfig(dict):\n",
        "    # Lưu tuỳ chọn xử lý waveform\n",
        "    pass\n",
        "\n",
        "\n",
        "class CepstralConfig(dict):\n",
        "    # Lưu tham số CQT\n",
        "    pass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class FeatureConfig:\n",
        "    sample_rate: int = 16000\n",
        "    spectral: SpectralConfig = field(\n",
        "        default_factory=lambda: SpectralConfig(\n",
        "            n_fft=1024,\n",
        "            hop_length=256,\n",
        "            win_length=1024,\n",
        "            n_mels=128,\n",
        "            f_min=20.0,\n",
        "            f_max=None,\n",
        "            power=2.0,\n",
        "        )\n",
        "    )\n",
        "    temporal: TemporalConfig = field(\n",
        "        default_factory=lambda: TemporalConfig(emphasis=True, highpass_cutoff=30.0)\n",
        "    )\n",
        "    cepstral: CepstralConfig = field(\n",
        "        default_factory=lambda: CepstralConfig(\n",
        "            hop_length=256,\n",
        "            n_bins=84,\n",
        "            bins_per_octave=12,\n",
        "            f_min=32.7,\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "class MultiBranchFeatureExtractor:\n",
        "    # Sinh đặc trưng mel, waveform và CQT cho ba nhánh mô hình\n",
        "    def __init__(self, config: FeatureConfig) -> None:\n",
        "        self.config = config\n",
        "        spec_cfg = config.spectral\n",
        "        self.mel_transform = torchaudio.transforms.MelSpectrogram(\n",
        "            sample_rate=config.sample_rate,\n",
        "            n_fft=spec_cfg.get(\"n_fft\", 1024),\n",
        "            hop_length=spec_cfg.get(\"hop_length\", 256),\n",
        "            win_length=spec_cfg.get(\"win_length\", spec_cfg.get(\"n_fft\", 1024)),\n",
        "            f_min=spec_cfg.get(\"f_min\", 20.0),\n",
        "            f_max=spec_cfg.get(\"f_max\"),\n",
        "            n_mels=spec_cfg.get(\"n_mels\", 128),\n",
        "            power=spec_cfg.get(\"power\", 2.0),\n",
        "            normalized=False,\n",
        "        )\n",
        "        temp_cfg = config.temporal\n",
        "        self.apply_pre_emphasis = temp_cfg.get(\"emphasis\", True)\n",
        "        self.highpass_cutoff = temp_cfg.get(\"highpass_cutoff\", 30.0)\n",
        "        self.cqt_cfg = config.cepstral\n",
        "\n",
        "    def __call__(self, waveform: Tensor) -> Dict[str, Tensor]:\n",
        "        waveform = ensure_mono(waveform)\n",
        "        mel = self._compute_mel_spectrogram(waveform)\n",
        "        temporal = self._prepare_temporal_branch(waveform)\n",
        "        cqt = self._compute_cqt(waveform)\n",
        "        return {\"spectral\": mel, \"temporal\": temporal, \"cepstral\": cqt}\n",
        "\n",
        "    def _compute_mel_spectrogram(self, waveform: Tensor) -> Tensor:\n",
        "        mel = self.mel_transform(waveform)\n",
        "        return torch.log1p(mel)\n",
        "\n",
        "    def _prepare_temporal_branch(self, waveform: Tensor) -> Tensor:\n",
        "        if self.apply_pre_emphasis:\n",
        "            waveform = torchaudio.functional.preemphasis(waveform, 0.97)\n",
        "        if self.highpass_cutoff is not None and self.highpass_cutoff > 0:\n",
        "            waveform = torchaudio.functional.highpass_biquad(\n",
        "                waveform,\n",
        "                sample_rate=self.config.sample_rate,\n",
        "                cutoff_freq=self.highpass_cutoff,\n",
        "            )\n",
        "        return waveform\n",
        "\n",
        "    def _compute_cqt(self, waveform: Tensor) -> Tensor:\n",
        "        y = waveform.squeeze(0).cpu().numpy()\n",
        "        cqt = librosa.cqt(\n",
        "            y,\n",
        "            sr=self.config.sample_rate,\n",
        "            hop_length=self.cqt_cfg.get(\"hop_length\", 256),\n",
        "            n_bins=self.cqt_cfg.get(\"n_bins\", 84),\n",
        "            bins_per_octave=self.cqt_cfg.get(\"bins_per_octave\", 12),\n",
        "            fmin=self.cqt_cfg.get(\"f_min\", 32.7),\n",
        "        )\n",
        "        magnitude = torch.from_numpy((abs(cqt) ** 2).astype(\"float32\"))\n",
        "        magnitude = torch.log1p(magnitude)\n",
        "        return magnitude.unsqueeze(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Dataset ASVspoof2019 LA\n",
        "Hợp nhất logic từ `src/data/asvspoof_dataset.py` với các chú thích chi tiết."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LA_LABELS = {\"bonafide\": 0, \"spoof\": 1}\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ASVExample:\n",
        "    utt_id: str\n",
        "    speaker_id: str\n",
        "    path: str\n",
        "    label: int\n",
        "    system_id: Optional[str] = None\n",
        "    attack_type: Optional[str] = None\n",
        "\n",
        "\n",
        "class ASVspoofLADataset(Dataset):\n",
        "    # Dataset PyTorch cho từng partition của ASVspoof2019 LA\n",
        "    def __init__(\n",
        "        self,\n",
        "        data_root: str,\n",
        "        partition: str,\n",
        "        feature_extractor: MultiBranchFeatureExtractor,\n",
        "        protocol_file: Optional[str] = None,\n",
        "        sample_rate: int = 16000,\n",
        "        max_duration: float = 6.0,\n",
        "        pad_mode: str = \"repeat\",\n",
        "        preload_waveforms: bool = False,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.data_root = data_root\n",
        "        self.partition = partition\n",
        "        self.sample_rate = sample_rate\n",
        "        self.max_num_samples = int(sample_rate * max_duration)\n",
        "        self.pad_mode = pad_mode\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.preload_waveforms = preload_waveforms\n",
        "\n",
        "        if protocol_file is None:\n",
        "            proto_dir = os.path.join(\n",
        "                data_root,\n",
        "                f\"ASVspoof2019_LA_{partition}\",\n",
        "                \"protocol\",\n",
        "            )\n",
        "            pattern = f\"ASVspoof2019.LA.cm.{partition}.trn.txt\"\n",
        "            candidates = [\n",
        "                os.path.join(proto_dir, pattern),\n",
        "                os.path.join(proto_dir, pattern.replace(\".trn\", \"\")),\n",
        "            ]\n",
        "            exists = [path for path in candidates if os.path.exists(path)]\n",
        "            if not exists:\n",
        "                raise FileNotFoundError(\n",
        "                    f\"Không tìm thấy protocol cho partition={partition}. Cần cung cấp protocol_file. Checked: {candidates}\"\n",
        "                )\n",
        "            protocol_file = exists[0]\n",
        "\n",
        "        self.protocol_file = protocol_file\n",
        "        self.examples = self._load_metadata()\n",
        "\n",
        "        if self.preload_waveforms:\n",
        "            self._waveform_cache: Dict[str, Tensor] = {}\n",
        "            for example in self.examples:\n",
        "                waveform, _ = load_audio(example.path, self.sample_rate, normalize=True)\n",
        "                waveform = pad_or_trim(waveform, self.max_num_samples, mode=self.pad_mode)\n",
        "                self._waveform_cache[example.utt_id] = waveform\n",
        "        else:\n",
        "            self._waveform_cache = {}\n",
        "\n",
        "    def _load_metadata(self) -> List[ASVExample]:\n",
        "        examples: List[ASVExample] = []\n",
        "        with open(self.protocol_file, \"r\", encoding=\"utf-8\") as handle:\n",
        "            reader = csv.reader(handle, delimiter=\" \")\n",
        "            for row in reader:\n",
        "                tokens = [tok for tok in row if tok]\n",
        "                if not tokens:\n",
        "                    continue\n",
        "                if len(tokens) == 4:\n",
        "                    speaker_id, utt_id, system_id, label_token = tokens\n",
        "                    attack_type = None\n",
        "                elif len(tokens) >= 5:\n",
        "                    speaker_id, utt_id, system_id, attack_type, label_token = tokens[:5]\n",
        "                else:\n",
        "                    raise ValueError(f\"Không thể parse dòng protocol: {tokens}\")\n",
        "\n",
        "                label_token = label_token.lower()\n",
        "                if label_token not in LA_LABELS:\n",
        "                    raise ValueError(f\"Nhãn không hợp lệ: {label_token}\")\n",
        "\n",
        "                partition_dir = f\"ASVspoof2019_LA_{self.partition}\"\n",
        "                audio_dir = os.path.join(self.data_root, partition_dir, \"flac\")\n",
        "                audio_path = os.path.join(audio_dir, f\"{utt_id}.flac\")\n",
        "                if not os.path.exists(audio_path):\n",
        "                    wav_path = os.path.join(audio_dir, f\"{utt_id}.wav\")\n",
        "                    if os.path.exists(wav_path):\n",
        "                        audio_path = wav_path\n",
        "                    else:\n",
        "                        raise FileNotFoundError(f\"Không tìm thấy file audio cho {utt_id}\")\n",
        "\n",
        "                examples.append(\n",
        "                    ASVExample(\n",
        "                        utt_id=utt_id,\n",
        "                        speaker_id=speaker_id,\n",
        "                        path=audio_path,\n",
        "                        label=LA_LABELS[label_token],\n",
        "                        system_id=system_id,\n",
        "                        attack_type=attack_type,\n",
        "                    )\n",
        "                )\n",
        "        return examples\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, index: int) -> Dict[str, Any]:\n",
        "        example = self.examples[index]\n",
        "        if example.utt_id in self._waveform_cache:\n",
        "            waveform = self._waveform_cache[example.utt_id]\n",
        "        else:\n",
        "            waveform, _ = load_audio(example.path, self.sample_rate, normalize=True)\n",
        "            waveform = pad_or_trim(waveform, self.max_num_samples, mode=self.pad_mode)\n",
        "\n",
        "        features = self.feature_extractor(waveform)\n",
        "        sample: Dict[str, Any] = {\n",
        "            \"utt_id\": example.utt_id,\n",
        "            \"speaker_id\": example.speaker_id,\n",
        "            \"label\": torch.tensor(example.label, dtype=torch.long),\n",
        "            \"features\": features,\n",
        "        }\n",
        "\n",
        "        metadata = {}\n",
        "        if example.system_id is not None:\n",
        "            metadata[\"system_id\"] = example.system_id\n",
        "        if example.attack_type is not None:\n",
        "            metadata[\"attack_type\"] = example.attack_type\n",
        "        if metadata:\n",
        "            sample[\"meta\"] = metadata\n",
        "        return sample\n",
        "\n",
        "\n",
        "def collate_fn(batch: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
        "    labels = torch.stack([item[\"label\"] for item in batch], dim=0)\n",
        "    branch_tensors: Dict[str, List[Tensor]] = {}\n",
        "    for item in batch:\n",
        "        for branch_name, tensor in item[\"features\"].items():\n",
        "            branch_tensors.setdefault(branch_name, []).append(tensor)\n",
        "    stacked_features = {\n",
        "        branch_name: torch.stack(tensors, dim=0)\n",
        "        for branch_name, tensors in branch_tensors.items()\n",
        "    }\n",
        "    output = {\n",
        "        \"features\": stacked_features,\n",
        "        \"labels\": labels,\n",
        "        \"utt_ids\": [item[\"utt_id\"] for item in batch],\n",
        "        \"speaker_ids\": [item[\"speaker_id\"] for item in batch],\n",
        "    }\n",
        "    metas = [item.get(\"meta\") for item in batch]\n",
        "    if any(meta is not None for meta in metas):\n",
        "        output[\"meta\"] = metas\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. DataModule tiện dụng\n",
        "Giữ nguyên cấu hình từ `src/data/datamodule.py` để tạo DataLoader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class PartitionConfig:\n",
        "    partition: str\n",
        "    protocol_file: Optional[str] = None\n",
        "    batch_size: int = 32\n",
        "    shuffle: bool = True\n",
        "    drop_last: bool = False\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DataModuleConfig:\n",
        "    data_root: str\n",
        "    sample_rate: int = 16000\n",
        "    max_duration: float = 6.0\n",
        "    pad_mode: str = \"repeat\"\n",
        "    num_workers: int = 4\n",
        "    pin_memory: bool = True\n",
        "    prefetch_factor: int = 2\n",
        "    feature: FeatureConfig = field(default_factory=FeatureConfig)\n",
        "    train: Optional[PartitionConfig] = None\n",
        "    valid: Optional[PartitionConfig] = None\n",
        "    test: Optional[PartitionConfig] = None\n",
        "    preload_waveforms: bool = False\n",
        "\n",
        "\n",
        "class ASVspoofDataModule:\n",
        "    # Chuẩn bị DataLoader cho train/dev/test với cùng cấu hình\n",
        "    def __init__(self, config: DataModuleConfig) -> None:\n",
        "        if config.train is None or config.valid is None:\n",
        "            raise ValueError(\"Cần cấu hình partition train và valid\")\n",
        "        self.config = config\n",
        "        self.feature_extractor = MultiBranchFeatureExtractor(config.feature)\n",
        "        self._datasets: Dict[str, ASVspoofLADataset] = {}\n",
        "\n",
        "    def setup(self, stage: Optional[str] = None) -> None:\n",
        "        if stage in (None, \"fit\"):\n",
        "            self._datasets[\"train\"] = self._build_dataset(self.config.train)\n",
        "            self._datasets[\"valid\"] = self._build_dataset(self.config.valid)\n",
        "        if stage in (None, \"test\") and self.config.test is not None:\n",
        "            self._datasets[\"test\"] = self._build_dataset(self.config.test)\n",
        "\n",
        "    def _build_dataset(self, part_cfg: PartitionConfig) -> ASVspoofLADataset:\n",
        "        return ASVspoofLADataset(\n",
        "            data_root=self.config.data_root,\n",
        "            partition=part_cfg.partition,\n",
        "            protocol_file=part_cfg.protocol_file,\n",
        "            feature_extractor=self.feature_extractor,\n",
        "            sample_rate=self.config.sample_rate,\n",
        "            max_duration=self.config.max_duration,\n",
        "            pad_mode=self.config.pad_mode,\n",
        "            preload_waveforms=self.config.preload_waveforms,\n",
        "        )\n",
        "\n",
        "    def train_dataloader(self) -> DataLoader:\n",
        "        return self._build_loader(self._datasets[\"train\"], self.config.train)\n",
        "\n",
        "    def val_dataloader(self) -> DataLoader:\n",
        "        return self._build_loader(self._datasets[\"valid\"], self.config.valid)\n",
        "\n",
        "    def test_dataloader(self) -> DataLoader:\n",
        "        if \"test\" not in self._datasets:\n",
        "            raise RuntimeError(\"Chưa setup test dataset\")\n",
        "        return self._build_loader(self._datasets[\"test\"], self.config.test)\n",
        "\n",
        "    def _build_loader(self, dataset: ASVspoofLADataset, part_cfg: PartitionConfig) -> DataLoader:\n",
        "        loader_kwargs = {\n",
        "            \"dataset\": dataset,\n",
        "            \"batch_size\": part_cfg.batch_size,\n",
        "            \"shuffle\": part_cfg.shuffle,\n",
        "            \"drop_last\": part_cfg.drop_last,\n",
        "            \"num_workers\": self.config.num_workers,\n",
        "            \"pin_memory\": self.config.pin_memory,\n",
        "            \"collate_fn\": collate_fn,\n",
        "        }\n",
        "        if self.config.num_workers > 0:\n",
        "            loader_kwargs[\"prefetch_factor\"] = self.config.prefetch_factor\n",
        "        return DataLoader(**loader_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Kiến trúc mô hình đa nhánh\n",
        "Sao chép từ `src/models/multi_branch_model.py` với chú thích cho từng thành phần."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def conv2d_block(\n",
        "    in_channels: int,\n",
        "    out_channels: int,\n",
        "    kernel_size: Tuple[int, int] = (3, 3),\n",
        "    stride: Tuple[int, int] = (1, 1),\n",
        "    padding: Tuple[int, int] = (1, 1),\n",
        "    dropout: float = 0.0,\n",
        ") -> nn.Sequential:\n",
        "    layers = [\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "    ]\n",
        "    if dropout > 0:\n",
        "        layers.append(nn.Dropout2d(dropout))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def conv1d_block(\n",
        "    in_channels: int,\n",
        "    out_channels: int,\n",
        "    kernel_size: int = 3,\n",
        "    stride: int = 1,\n",
        "    padding: int = 1,\n",
        "    dropout: float = 0.0,\n",
        ") -> nn.Sequential:\n",
        "    layers = [\n",
        "        nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding),\n",
        "        nn.BatchNorm1d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "    ]\n",
        "    if dropout > 0:\n",
        "        layers.append(nn.Dropout(dropout))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "class SpectralBranch(nn.Module):\n",
        "    def __init__(self, in_channels: int = 1, hidden_dim: int = 256) -> None:\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            conv2d_block(in_channels, 32, dropout=0.1),\n",
        "            nn.MaxPool2d((2, 2)),\n",
        "            conv2d_block(32, 64, dropout=0.15),\n",
        "            nn.MaxPool2d((2, 2)),\n",
        "            conv2d_block(64, 128, dropout=0.2),\n",
        "            conv2d_block(128, 128, dropout=0.2),\n",
        "        )\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128, hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self.proj(self.pool(self.features(x)))\n",
        "\n",
        "\n",
        "class TemporalBranch(nn.Module):\n",
        "    def __init__(self, in_channels: int = 1, hidden_dim: int = 256) -> None:\n",
        "        super().__init__()\n",
        "        self.conv_stack = nn.Sequential(\n",
        "            conv1d_block(in_channels, 32, kernel_size=11, stride=2, padding=5, dropout=0.1),\n",
        "            conv1d_block(32, 64, kernel_size=9, stride=2, padding=4, dropout=0.1),\n",
        "            conv1d_block(64, 128, kernel_size=7, stride=2, padding=3, dropout=0.15),\n",
        "            conv1d_block(128, 128, kernel_size=5, stride=1, padding=2, dropout=0.15),\n",
        "        )\n",
        "        self.temporal_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128, hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self.proj(self.temporal_pool(self.conv_stack(x)))\n",
        "\n",
        "\n",
        "class CepstralBranch(nn.Module):\n",
        "    def __init__(self, in_channels: int = 1, hidden_dim: int = 256) -> None:\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            conv2d_block(in_channels, 32, kernel_size=(3, 5), padding=(1, 2), dropout=0.1),\n",
        "            nn.MaxPool2d((2, 2)),\n",
        "            conv2d_block(32, 64, kernel_size=(3, 5), padding=(1, 2), dropout=0.15),\n",
        "            nn.MaxPool2d((2, 2)),\n",
        "            conv2d_block(64, 128, kernel_size=(3, 3), padding=(1, 1), dropout=0.2),\n",
        "        )\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128, hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self.proj(self.pool(self.features(x)))\n",
        "\n",
        "\n",
        "class AttentionFusion(nn.Module):\n",
        "    def __init__(self, embed_dim: int, attn_dim: int = 128, dropout: float = 0.1) -> None:\n",
        "        super().__init__()\n",
        "        self.proj = nn.Linear(embed_dim, attn_dim)\n",
        "        self.score = nn.Linear(attn_dim, 1, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, branch_embeddings: Tensor) -> Tuple[Tensor, Tensor]:\n",
        "        attn_hidden = torch.tanh(self.proj(branch_embeddings))\n",
        "        scores = self.score(attn_hidden).squeeze(-1)\n",
        "        weights = torch.softmax(scores, dim=-1)\n",
        "        branch_embeddings = self.dropout(branch_embeddings)\n",
        "        fused = torch.sum(branch_embeddings * weights.unsqueeze(-1), dim=1)\n",
        "        return fused, weights\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class MultiBranchModelConfig:\n",
        "    embed_dim: int = 256\n",
        "    attn_dim: int = 128\n",
        "    num_classes: int = 2\n",
        "    classifier_hidden: int = 128\n",
        "    dropout: float = 0.3\n",
        "\n",
        "\n",
        "class MultiBranchAttentionModel(nn.Module):\n",
        "    # Kiến trúc đa nhánh với attention fusion\n",
        "    def __init__(self, config: MultiBranchModelConfig) -> None:\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.branches = nn.ModuleDict(\n",
        "            {\n",
        "                \"spectral\": SpectralBranch(hidden_dim=config.embed_dim),\n",
        "                \"temporal\": TemporalBranch(hidden_dim=config.embed_dim),\n",
        "                \"cepstral\": CepstralBranch(hidden_dim=config.embed_dim),\n",
        "            }\n",
        "        )\n",
        "        self.fusion = AttentionFusion(config.embed_dim, config.attn_dim, dropout=config.dropout)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(config.embed_dim, config.classifier_hidden),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(config.dropout),\n",
        "            nn.Linear(config.classifier_hidden, config.num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, features: Dict[str, Tensor]) -> Dict[str, Tensor]:\n",
        "        branch_outputs = []\n",
        "        attn_order = []\n",
        "        for branch_name, module in self.branches.items():\n",
        "            if branch_name not in features:\n",
        "                raise KeyError(f\"Thiếu nhánh {branch_name} trong input\")\n",
        "            branch_out = module(features[branch_name])\n",
        "            branch_outputs.append(branch_out.unsqueeze(1))\n",
        "            attn_order.append(branch_name)\n",
        "        branch_stack = torch.cat(branch_outputs, dim=1)\n",
        "        fused, weights = self.fusion(branch_stack)\n",
        "        logits = self.classifier(fused)\n",
        "        return {\n",
        "            \"logits\": logits,\n",
        "            \"fused\": fused,\n",
        "            \"attention_weights\": weights,\n",
        "            \"branch_embeddings\": branch_stack,\n",
        "            \"branch_order\": attn_order,\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Các hàm metric\n",
        "Bao gồm accuracy và EER như trong `src/utils/metrics.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_accuracy(logits: Tensor, labels: Tensor) -> float:\n",
        "    preds = torch.argmax(logits, dim=1)\n",
        "    correct = (preds == labels).sum().item()\n",
        "    return correct / labels.numel()\n",
        "\n",
        "\n",
        "def compute_eer(scores: Tensor, labels: Tensor) -> float:\n",
        "    labels_np = labels.detach().cpu().numpy().astype(np.int32)\n",
        "    scores_np = scores.detach().cpu().numpy()\n",
        "    order = np.argsort(scores_np)[::-1]\n",
        "    sorted_labels = labels_np[order]\n",
        "    positives = sorted_labels.sum()\n",
        "    negatives = len(sorted_labels) - positives\n",
        "    if positives == 0 or negatives == 0:\n",
        "        return 0.0\n",
        "    false_accepts = 0\n",
        "    false_rejects = positives\n",
        "    min_gap = 1.0\n",
        "    eer = 1.0\n",
        "    for label in sorted_labels:\n",
        "        if label == 1:\n",
        "            false_rejects -= 1\n",
        "        else:\n",
        "            false_accepts += 1\n",
        "        far = false_accepts / negatives\n",
        "        frr = false_rejects / positives\n",
        "        gap = abs(far - frr)\n",
        "        if gap < min_gap:\n",
        "            min_gap = gap\n",
        "            eer = (far + frr) / 2.0\n",
        "    return float(eer)\n",
        "\n",
        "\n",
        "def aggregate_metrics(logits: Tensor, labels: Tensor) -> Dict[str, float]:\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    spoof_scores = probs[:, 1]\n",
        "    accuracy = compute_accuracy(logits, labels)\n",
        "    eer = compute_eer(spoof_scores, labels)\n",
        "    return {\"accuracy\": accuracy, \"eer\": eer}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Trainer\n",
        "Định nghĩa lớp Trainer gom từ `src/training/engine.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class OptimizerConfig:\n",
        "    lr: float = 1e-4\n",
        "    weight_decay: float = 1e-5\n",
        "    betas: Tuple[float, float] = (0.9, 0.98)\n",
        "    eps: float = 1e-8\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class SchedulerConfig:\n",
        "    use_cosine: bool = True\n",
        "    min_lr: float = 1e-6\n",
        "    t_max: Optional[int] = None\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class TrainingConfig:\n",
        "    epochs: int = 50\n",
        "    device: Optional[str] = None\n",
        "    log_interval: int = 20\n",
        "    grad_clip: float = 5.0\n",
        "    mixed_precision: bool = True\n",
        "    checkpoint_dir: str = \"checkpoints\"\n",
        "    best_metric: str = \"eer\"\n",
        "    patience: int = 10\n",
        "    resume_from: Optional[str] = None\n",
        "    save_every: int = 0\n",
        "    history: List[Dict[str, float]] = field(default_factory=list)\n",
        "    evaluate_on_test: bool = False\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: nn.Module,\n",
        "        train_config: TrainingConfig,\n",
        "        optim_config: OptimizerConfig,\n",
        "        scheduler_config: SchedulerConfig,\n",
        "    ) -> None:\n",
        "        self.model = model\n",
        "        self.train_config = train_config\n",
        "        self.optim_config = optim_config\n",
        "        self.scheduler_config = scheduler_config\n",
        "        device_str = train_config.device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.device = torch.device(device_str)\n",
        "        self.model.to(self.device)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.scaler = torch.cuda.amp.GradScaler(\n",
        "            enabled=(self.device.type == \"cuda\" and train_config.mixed_precision)\n",
        "        )\n",
        "        self.best_metric_value: Optional[float] = None\n",
        "        self.best_epoch: Optional[int] = None\n",
        "\n",
        "    def fit(self, datamodule: ASVspoofDataModule) -> Dict[str, List[Dict[str, float]]]:\n",
        "        datamodule.setup(stage=\"fit\")\n",
        "        train_loader = datamodule.train_dataloader()\n",
        "        valid_loader = datamodule.val_dataloader()\n",
        "        optimizer = torch.optim.AdamW(\n",
        "            self.model.parameters(),\n",
        "            lr=self.optim_config.lr,\n",
        "            weight_decay=self.optim_config.weight_decay,\n",
        "            betas=self.optim_config.betas,\n",
        "            eps=self.optim_config.eps,\n",
        "        )\n",
        "        scheduler = self._build_scheduler(optimizer)\n",
        "        os.makedirs(self.train_config.checkpoint_dir, exist_ok=True)\n",
        "        history = {\"train\": [], \"valid\": []}\n",
        "        patience_counter = 0\n",
        "        for epoch in range(1, self.train_config.epochs + 1):\n",
        "            train_metrics = self._run_epoch(\n",
        "                loader=train_loader,\n",
        "                optimizer=optimizer,\n",
        "                scheduler=scheduler,\n",
        "                epoch=epoch,\n",
        "                train=True,\n",
        "            )\n",
        "            valid_metrics = self._run_epoch(\n",
        "                loader=valid_loader,\n",
        "                optimizer=None,\n",
        "                scheduler=None,\n",
        "                epoch=epoch,\n",
        "                train=False,\n",
        "            )\n",
        "            history[\"train\"].append(train_metrics)\n",
        "            history[\"valid\"].append(valid_metrics)\n",
        "            self.train_config.history.append(\n",
        "                {\"epoch\": epoch, **train_metrics, **{f\"val_{k}\": v for k, v in valid_metrics.items()}}\n",
        "            )\n",
        "            current_metric = valid_metrics.get(self.train_config.best_metric)\n",
        "            if current_metric is None:\n",
        "                raise KeyError(\n",
        "                    f\"Không tìm thấy metric {self.train_config.best_metric} trong valid metrics\"\n",
        "                )\n",
        "            if self._is_better(current_metric):\n",
        "                self.best_metric_value = current_metric\n",
        "                self.best_epoch = epoch\n",
        "                patience_counter = 0\n",
        "                self._save_checkpoint(optimizer, epoch, best=True)\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "            if self.train_config.save_every > 0 and epoch % self.train_config.save_every == 0:\n",
        "                self._save_checkpoint(optimizer, epoch, best=False)\n",
        "            if scheduler is not None and getattr(scheduler, \"step\", None) is not None:\n",
        "                scheduler.step()\n",
        "            if patience_counter >= self.train_config.patience:\n",
        "                print(f\"[Trainer] Early stopping ở epoch {epoch}.\")\n",
        "                break\n",
        "        return history\n",
        "\n",
        "    def evaluate(self, datamodule: ASVspoofDataModule) -> Dict[str, float]:\n",
        "        datamodule.setup(stage=\"test\")\n",
        "        test_loader = datamodule.test_dataloader()\n",
        "        return self._run_epoch(loader=test_loader, optimizer=None, scheduler=None, epoch=0, train=False)\n",
        "\n",
        "    def _run_epoch(\n",
        "        self,\n",
        "        loader,\n",
        "        optimizer,\n",
        "        scheduler,\n",
        "        epoch: int,\n",
        "        train: bool,\n",
        "    ) -> Dict[str, float]:\n",
        "        self.model.train(mode=train)\n",
        "        total_loss = 0.0\n",
        "        total_samples = 0\n",
        "        all_logits: List[Tensor] = []\n",
        "        all_labels: List[Tensor] = []\n",
        "        for step, batch in enumerate(loader, start=1):\n",
        "            features = {\n",
        "                name: tensor.to(self.device, non_blocking=True)\n",
        "                for name, tensor in batch[\"features\"].items()\n",
        "            }\n",
        "            labels = batch[\"labels\"].to(self.device, non_blocking=True)\n",
        "            batch_size = labels.size(0)\n",
        "            with torch.set_grad_enabled(train):\n",
        "                with torch.cuda.amp.autocast(enabled=self.scaler.is_enabled()):\n",
        "                    outputs = self.model(features)\n",
        "                    logits = outputs[\"logits\"]\n",
        "                    loss = self.criterion(logits, labels)\n",
        "                if train:\n",
        "                    self.scaler.scale(loss).backward()\n",
        "                    if self.train_config.grad_clip > 0:\n",
        "                        self.scaler.unscale_(optimizer)\n",
        "                        torch.nn.utils.clip_grad_norm_(\n",
        "                            self.model.parameters(), self.train_config.grad_clip\n",
        "                        )\n",
        "                    self.scaler.step(optimizer)\n",
        "                    self.scaler.update()\n",
        "                    optimizer.zero_grad(set_to_none=True)\n",
        "            total_loss += loss.item() * batch_size\n",
        "            total_samples += batch_size\n",
        "            all_logits.append(logits.detach().cpu())\n",
        "            all_labels.append(labels.detach().cpu())\n",
        "            if train and self.train_config.log_interval and step % self.train_config.log_interval == 0:\n",
        "                current_loss = total_loss / total_samples\n",
        "                print(\n",
        "                    f\"[Epoch {epoch}] Step {step}/{len(loader)} Loss: {current_loss:.4f} \"\n",
        "                    f\"LR: {optimizer.param_groups[0]['lr']:.2e}\"\n",
        "                )\n",
        "        avg_loss = total_loss / max(total_samples, 1)\n",
        "        logits_tensor = torch.cat(all_logits, dim=0) if all_logits else torch.empty((0, 2))\n",
        "        labels_tensor = torch.cat(all_labels, dim=0) if all_labels else torch.empty((0,), dtype=torch.long)\n",
        "        metrics = (\n",
        "            aggregate_metrics(logits_tensor, labels_tensor)\n",
        "            if total_samples > 0\n",
        "            else {\"accuracy\": 0.0, \"eer\": 0.0}\n",
        "        )\n",
        "        metrics[\"loss\"] = avg_loss\n",
        "        return metrics\n",
        "\n",
        "    def _is_better(self, value: float) -> bool:\n",
        "        if self.best_metric_value is None:\n",
        "            return True\n",
        "        if self.train_config.best_metric in {\"loss\", \"eer\"}:\n",
        "            return value < self.best_metric_value\n",
        "        return value > self.best_metric_value\n",
        "\n",
        "    def _save_checkpoint(self, optimizer, epoch: int, best: bool) -> None:\n",
        "        state = {\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state_dict\": self.model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict() if optimizer is not None else None,\n",
        "            \"best_metric\": self.best_metric_value,\n",
        "            \"best_epoch\": self.best_epoch,\n",
        "        }\n",
        "        suffix = \"best\" if best else f\"epoch_{epoch:03d}\"\n",
        "        path = os.path.join(self.train_config.checkpoint_dir, f\"checkpoint_{suffix}.pt\")\n",
        "        torch.save(state, path)\n",
        "        tag = \"BEST\" if best else \"SNAPSHOT\"\n",
        "        print(f\"[Trainer] Đã lưu checkpoint ({tag}) tại {path}\")\n",
        "\n",
        "    def _build_scheduler(self, optimizer):\n",
        "        if not self.scheduler_config.use_cosine:\n",
        "            return None\n",
        "        t_max = self.scheduler_config.t_max or self.train_config.epochs\n",
        "        return torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "            optimizer,\n",
        "            T_max=t_max,\n",
        "            eta_min=self.scheduler_config.min_lr,\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Hàm hỗ trợ đọc YAML cấu hình (tuỳ chọn)\n",
        "Giống `train.py` để dễ dàng load config từ file khi chạy trên Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_yaml_config(path: str) -> Dict[str, Any]:\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as handle:\n",
        "        return yaml.safe_load(handle)\n",
        "\n",
        "\n",
        "def build_feature_config(cfg: Dict[str, Any]) -> FeatureConfig:\n",
        "    base = FeatureConfig()\n",
        "    spectral = {**base.spectral, **cfg.get(\"spectral\", {})}\n",
        "    temporal = {**base.temporal, **cfg.get(\"temporal\", {})}\n",
        "    cepstral = {**base.cepstral, **cfg.get(\"cepstral\", {})}\n",
        "    return FeatureConfig(\n",
        "        sample_rate=cfg.get(\"sample_rate\", base.sample_rate),\n",
        "        spectral=SpectralConfig(**spectral),\n",
        "        temporal=TemporalConfig(**temporal),\n",
        "        cepstral=CepstralConfig(**cepstral),\n",
        "    )\n",
        "\n",
        "\n",
        "def build_partition_config(cfg: Dict[str, Any]) -> PartitionConfig:\n",
        "    return PartitionConfig(\n",
        "        partition=cfg[\"partition\"],\n",
        "        protocol_file=cfg.get(\"protocol_file\"),\n",
        "        batch_size=cfg.get(\"batch_size\", 32),\n",
        "        shuffle=cfg.get(\"shuffle\", True),\n",
        "        drop_last=cfg.get(\"drop_last\", False),\n",
        "    )\n",
        "\n",
        "\n",
        "def build_data_module_config(cfg: Dict[str, Any]) -> DataModuleConfig:\n",
        "    feature_cfg = build_feature_config(cfg.get(\"feature\", {}))\n",
        "    train_cfg = build_partition_config(cfg[\"train\"])\n",
        "    valid_cfg = build_partition_config(cfg[\"valid\"])\n",
        "    test_cfg = build_partition_config(cfg[\"test\"]) if cfg.get(\"test\") else None\n",
        "    return DataModuleConfig(\n",
        "        data_root=cfg[\"data_root\"],\n",
        "        sample_rate=cfg.get(\"sample_rate\", feature_cfg.sample_rate),\n",
        "        max_duration=cfg.get(\"max_duration\", 6.0),\n",
        "        pad_mode=cfg.get(\"pad_mode\", \"repeat\"),\n",
        "        num_workers=cfg.get(\"num_workers\", 4),\n",
        "        pin_memory=cfg.get(\"pin_memory\", True),\n",
        "        prefetch_factor=cfg.get(\"prefetch_factor\", 2),\n",
        "        feature=feature_cfg,\n",
        "        train=train_cfg,\n",
        "        valid=valid_cfg,\n",
        "        test=test_cfg,\n",
        "        preload_waveforms=cfg.get(\"preload_waveforms\", False),\n",
        "    )\n",
        "\n",
        "\n",
        "def build_model_config(cfg: Dict[str, Any]) -> MultiBranchModelConfig:\n",
        "    base = MultiBranchModelConfig()\n",
        "    return MultiBranchModelConfig(\n",
        "        embed_dim=cfg.get(\"embed_dim\", base.embed_dim),\n",
        "        attn_dim=cfg.get(\"attn_dim\", base.attn_dim),\n",
        "        num_classes=cfg.get(\"num_classes\", base.num_classes),\n",
        "        classifier_hidden=cfg.get(\"classifier_hidden\", base.classifier_hidden),\n",
        "        dropout=cfg.get(\"dropout\", base.dropout),\n",
        "    )\n",
        "\n",
        "\n",
        "def build_training_config(cfg: Dict[str, Any]) -> TrainingConfig:\n",
        "    base = TrainingConfig()\n",
        "    return TrainingConfig(\n",
        "        epochs=cfg.get(\"epochs\", base.epochs),\n",
        "        device=cfg.get(\"device\", base.device),\n",
        "        log_interval=cfg.get(\"log_interval\", base.log_interval),\n",
        "        grad_clip=cfg.get(\"grad_clip\", base.grad_clip),\n",
        "        mixed_precision=cfg.get(\"mixed_precision\", base.mixed_precision),\n",
        "        checkpoint_dir=cfg.get(\"checkpoint_dir\", base.checkpoint_dir),\n",
        "        best_metric=cfg.get(\"best_metric\", base.best_metric),\n",
        "        patience=cfg.get(\"patience\", base.patience),\n",
        "        resume_from=cfg.get(\"resume_from\", base.resume_from),\n",
        "        save_every=cfg.get(\"save_every\", base.save_every),\n",
        "        evaluate_on_test=cfg.get(\"evaluate_on_test\", base.evaluate_on_test),\n",
        "    )\n",
        "\n",
        "\n",
        "def build_optimizer_config(cfg: Dict[str, Any]) -> OptimizerConfig:\n",
        "    base = OptimizerConfig()\n",
        "    return OptimizerConfig(\n",
        "        lr=cfg.get(\"lr\", base.lr),\n",
        "        weight_decay=cfg.get(\"weight_decay\", base.weight_decay),\n",
        "        betas=tuple(cfg.get(\"betas\", base.betas)),\n",
        "        eps=cfg.get(\"eps\", base.eps),\n",
        "    )\n",
        "\n",
        "\n",
        "def build_scheduler_config(cfg: Dict[str, Any], total_epochs: int) -> SchedulerConfig:\n",
        "    base = SchedulerConfig()\n",
        "    use_cosine = cfg.get(\"use_cosine\", base.use_cosine)\n",
        "    min_lr = cfg.get(\"min_lr\", base.min_lr)\n",
        "    t_max = cfg.get(\"t_max\", total_epochs if base.t_max is None else base.t_max)\n",
        "    return SchedulerConfig(use_cosine=use_cosine, min_lr=min_lr, t_max=t_max)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Ví dụ chạy nhanh\n",
        "Cell dưới đây minh hoạ cách kết nối tất cả thành phần. Bạn cần cập nhật `DATA_ROOT` trỏ tới thư mục chứa dataset trên Kaggle (ví dụ `/kaggle/input/asvspoof2019`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_ROOT = \"/kaggle/input/asvspoof2019\"  # cập nhật đường dẫn thực tế\n",
        "USE_CONFIG = False  # Đổi sang True nếu bạn muốn load YAML\n",
        "\n",
        "if USE_CONFIG:\n",
        "    CONFIG_PATH = \"/kaggle/input/asvspoof-config/config.yaml\"\n",
        "    config_dict = load_yaml_config(CONFIG_PATH)\n",
        "    data_cfg = build_data_module_config(config_dict[\"data\"])\n",
        "    model_cfg = build_model_config(config_dict.get(\"model\", {}))\n",
        "    training_cfg = build_training_config(config_dict.get(\"training\", {}))\n",
        "    optimizer_cfg = build_optimizer_config(config_dict.get(\"optimizer\", {}))\n",
        "    scheduler_cfg = build_scheduler_config(\n",
        "        config_dict.get(\"scheduler\", {}), total_epochs=training_cfg.epochs\n",
        "    )\n",
        "else:\n",
        "    data_cfg = DataModuleConfig(\n",
        "        data_root=DATA_ROOT,\n",
        "        train=PartitionConfig(partition=\"train\"),\n",
        "        valid=PartitionConfig(partition=\"dev\"),\n",
        "        test=PartitionConfig(partition=\"eval\"),\n",
        "        num_workers=2,\n",
        "        preload_waveforms=False,\n",
        "    )\n",
        "    model_cfg = MultiBranchModelConfig()\n",
        "    training_cfg = TrainingConfig(epochs=5, log_interval=5, evaluate_on_test=True)\n",
        "    optimizer_cfg = OptimizerConfig(lr=1e-4)\n",
        "    scheduler_cfg = SchedulerConfig(use_cosine=True, min_lr=1e-6)\n",
        "\n",
        "datamodule = ASVspoofDataModule(data_cfg)\n",
        "model = MultiBranchAttentionModel(model_cfg)\n",
        "trainer = Trainer(model, training_cfg, optimizer_cfg, scheduler_cfg)\n",
        "\n",
        "print(\"Pipeline đã sẵn sàng. Gọi trainer.fit(datamodule) để bắt đầu huấn luyện.\")\n",
        "print(\"Cảnh báo: việc huấn luyện đầy đủ cần nhiều thời gian và tài nguyên.\")\n",
        "# history = trainer.fit(datamodule)\n",
        "# if training_cfg.evaluate_on_test:\n",
        "#     metrics = trainer.evaluate(datamodule)\n",
        "#     print(\"Test metrics:\", metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "**Gợi ý:** Sau khi chạy, bạn có thể lưu checkpoint tốt nhất từ thư mục `checkpoints/` về Kaggle Output bằng `shutil.copy` nếu cần nộp kết quả."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}