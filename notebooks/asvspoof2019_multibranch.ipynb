{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASVspoof 2019 LA – Multi-branch Attention Model\n",
    "\n",
    "Notebook này tái cấu trúc toàn bộ project huấn luyện mô hình đa nhánh phát hiện giả mạo giọng nói sang định dạng `.ipynb` để có thể chạy trực tiếp trên Kaggle hoặc các môi trường notebook khác. Mọi phần mã nguồn trong thư mục `src/` và script `train.py` đều đã được tổ chức lại thành các cell có chú thích rõ ràng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chuẩn bị môi trường\n",
    "Chạy cell bên dưới để cài đặt các phụ thuộc cần thiết. Bạn có thể tuỳ chỉnh danh sách nếu môi trường đã có sẵn một số thư viện."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Nếu chạy trên Kaggle hoặc môi trường mới, bỏ comment dòng dưới để cài đặt.\n",
    "# !pip install torch torchaudio numpy scipy pandas PyYAML librosa soundfile tqdm matplotlib tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Thư viện và cấu hình toàn cục"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import csv\n",
    "import math\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Tuple, TypedDict\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import yaml\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Đảm bảo reproducibility (có thể điều chỉnh tuỳ nhu cầu)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cấu hình đặc trưng và xử lý âm thanh\n",
    "Các cell dưới đây tương ứng với `src/data/features.py` và `src/utils/audio.py`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SpectralConfig(TypedDict, total=False):\n",
    "    n_fft: int\n",
    "    hop_length: int\n",
    "    win_length: int\n",
    "    n_mels: int\n",
    "    f_min: float\n",
    "    f_max: Optional[float]\n",
    "    power: float\n",
    "\n",
    "\n",
    "class TemporalConfig(TypedDict, total=False):\n",
    "    emphasis: bool\n",
    "    highpass_cutoff: float\n",
    "\n",
    "\n",
    "class CepstralConfig(TypedDict, total=False):\n",
    "    hop_length: int\n",
    "    n_bins: int\n",
    "    bins_per_octave: int\n",
    "    f_min: float\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FeatureConfig:\n",
    "    \"\"\"Tập hợp các tham số dựng đặc trưng cho từng nhánh.\"\"\"\n",
    "\n",
    "    sample_rate: int = 16000\n",
    "    spectral: SpectralConfig = field(\n",
    "        default_factory=lambda: SpectralConfig(\n",
    "            n_fft=1024,\n",
    "            hop_length=256,\n",
    "            win_length=1024,\n",
    "            n_mels=128,\n",
    "            f_min=20.0,\n",
    "            f_max=None,\n",
    "            power=2.0,\n",
    "        )\n",
    "    )\n",
    "    temporal: TemporalConfig = field(\n",
    "        default_factory=lambda: TemporalConfig(\n",
    "            emphasis=True,\n",
    "            highpass_cutoff=30.0,\n",
    "        )\n",
    "    )\n",
    "    cepstral: CepstralConfig = field(\n",
    "        default_factory=lambda: CepstralConfig(\n",
    "            hop_length=256,\n",
    "            n_bins=84,\n",
    "            bins_per_octave=12,\n",
    "            f_min=32.7,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ensure_mono(waveform: Tensor) -> Tensor:\n",
    "    \"\"\"Chuyển waveform nhiều kênh về mono bằng cách trung bình theo trục kênh.\"\"\"\n",
    "    if waveform.size(0) == 1:\n",
    "        return waveform\n",
    "    return waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "\n",
    "def load_audio(path: str, target_sample_rate: int, normalize: bool = True) -> Tuple[Tensor, int]:\n",
    "    \"\"\"Đọc audio, resample nếu cần và chuẩn hoá biên độ về [-1, 1].\"\"\"\n",
    "    waveform, sample_rate = torchaudio.load(path)\n",
    "    if sample_rate != target_sample_rate:\n",
    "        resampler = torchaudio.transforms.Resample(sample_rate, target_sample_rate)\n",
    "        waveform = resampler(waveform)\n",
    "        sample_rate = target_sample_rate\n",
    "\n",
    "    waveform = ensure_mono(waveform)\n",
    "    if normalize:\n",
    "        peak = waveform.abs().max()\n",
    "        if peak > 0:\n",
    "            waveform = waveform / peak\n",
    "    return waveform, sample_rate\n",
    "\n",
    "\n",
    "def pad_or_trim(waveform: Tensor, target_num_samples: int, mode: str = \"repeat\") -> Tensor:\n",
    "    \"\"\"Đưa waveform về độ dài cố định bằng cách pad hoặc cắt.\"\"\"\n",
    "    current = waveform.size(-1)\n",
    "    if current == target_num_samples:\n",
    "        return waveform\n",
    "    if current > target_num_samples:\n",
    "        return waveform[..., :target_num_samples]\n",
    "\n",
    "    diff = target_num_samples - current\n",
    "    if mode == \"zeros\":\n",
    "        padded = torch.nn.functional.pad(waveform, (0, diff))\n",
    "    elif mode == \"reflect\":\n",
    "        padded = torch.nn.functional.pad(waveform, (0, diff), mode=\"reflect\")\n",
    "    elif mode == \"repeat\":\n",
    "        repeats = math.ceil(target_num_samples / current)\n",
    "        padded = waveform.repeat(1, repeats)[..., :target_num_samples]\n",
    "    else:\n",
    "        raise ValueError(f\"pad_mode không được hỗ trợ: {mode}\")\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "MultiBranchFeatures = Dict[str, Tensor]\n",
    "\n",
    "\n",
    "class MultiBranchFeatureExtractor:\n",
    "    \"\"\"Sinh đặc trưng cho ba nhánh: spectral (Mel), temporal (sóng), cepstral (CQT).\"\"\"\n",
    "\n",
    "    def __init__(self, config: FeatureConfig) -> None:\n",
    "        self.config = config\n",
    "        spec_cfg = config.spectral\n",
    "        self.mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=config.sample_rate,\n",
    "            n_fft=spec_cfg.get(\"n_fft\", 1024),\n",
    "            hop_length=spec_cfg.get(\"hop_length\", 256),\n",
    "            win_length=spec_cfg.get(\"win_length\", spec_cfg.get(\"n_fft\", 1024)),\n",
    "            f_min=spec_cfg.get(\"f_min\", 20.0),\n",
    "            f_max=spec_cfg.get(\"f_max\"),\n",
    "            n_mels=spec_cfg.get(\"n_mels\", 128),\n",
    "            power=spec_cfg.get(\"power\", 2.0),\n",
    "            normalized=False,\n",
    "        )\n",
    "\n",
    "        temp_cfg = config.temporal\n",
    "        self.apply_pre_emphasis = temp_cfg.get(\"emphasis\", True)\n",
    "        self.highpass_cutoff = temp_cfg.get(\"highpass_cutoff\", 30.0)\n",
    "        self.cqt_cfg = config.cepstral\n",
    "\n",
    "    def __call__(self, waveform: Tensor) -> MultiBranchFeatures:\n",
    "        waveform = ensure_mono(waveform)\n",
    "        mel = self._compute_mel_spectrogram(waveform)\n",
    "        temporal = self._prepare_temporal_branch(waveform)\n",
    "        cqt = self._compute_cqt(waveform)\n",
    "        return {\"spectral\": mel, \"temporal\": temporal, \"cepstral\": cqt}\n",
    "\n",
    "    def _compute_mel_spectrogram(self, waveform: Tensor) -> Tensor:\n",
    "        mel = self.mel_transform(waveform)\n",
    "        return torch.log1p(mel)\n",
    "\n",
    "    def _prepare_temporal_branch(self, waveform: Tensor) -> Tensor:\n",
    "        output = waveform\n",
    "        if self.apply_pre_emphasis:\n",
    "            output = torchaudio.functional.preemphasis(output, 0.97)\n",
    "        if self.highpass_cutoff is not None and self.highpass_cutoff > 0:\n",
    "            output = torchaudio.functional.highpass_biquad(\n",
    "                output,\n",
    "                sample_rate=self.config.sample_rate,\n",
    "                cutoff_freq=self.highpass_cutoff,\n",
    "            )\n",
    "        return output\n",
    "\n",
    "    def _compute_cqt(self, waveform: Tensor) -> Tensor:\n",
    "        y = waveform.squeeze(0).cpu().numpy()\n",
    "        cqt = librosa.cqt(\n",
    "            y,\n",
    "            sr=self.config.sample_rate,\n",
    "            hop_length=self.cqt_cfg.get(\"hop_length\", 256),\n",
    "            n_bins=self.cqt_cfg.get(\"n_bins\", 84),\n",
    "            bins_per_octave=self.cqt_cfg.get(\"bins_per_octave\", 12),\n",
    "            fmin=self.cqt_cfg.get(\"f_min\", 32.7),\n",
    "        )\n",
    "        magnitude = torch.from_numpy((np.abs(cqt) ** 2).astype(\"float32\"))\n",
    "        magnitude = torch.log1p(magnitude)\n",
    "        return magnitude.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset và DataModule\n",
    "Các cell tương ứng với `src/data/asvspoof_dataset.py` và `src/data/datamodule.py`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "LA_LABELS = {\"bonafide\": 0, \"spoof\": 1}\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DatasetSpec:\n",
    "    partition_dir_template: str\n",
    "    protocol_patterns: Tuple[str, ...]\n",
    "    audio_subdirs: Tuple[str, ...] = (\"\", \"flac\", \"wav\")\n",
    "    audio_extensions: Tuple[str, ...] = (\".flac\", \".wav\")\n",
    "    protocol_dir_templates: Tuple[str, ...] = (\n",
    "        \"{partition_dir}/protocol\",\n",
    "        \"{partition_dir}\",\n",
    "    )\n",
    "\n",
    "\n",
    "DEFAULT_DATASET_VARIANT = \"ASVspoof2019_LA\"\n",
    "\n",
    "\n",
    "DATASET_SPECS: Dict[str, DatasetSpec] = {\n",
    "    \"ASVspoof2019_LA\": DatasetSpec(\n",
    "        partition_dir_template=\"ASVspoof2019_LA_{partition}\",\n",
    "        protocol_patterns=(\n",
    "            \"ASVspoof2019.LA.cm.{partition}.trn.txt\",\n",
    "            \"ASVspoof2019.LA.cm.{partition}.trl.txt\",\n",
    "            \"ASVspoof2019.LA.cm.{partition}.txt\",\n",
    "        ),\n",
    "        audio_subdirs=(\"\", \"flac\", \"wav\"),\n",
    "        audio_extensions=(\".flac\", \".wav\"),\n",
    "        protocol_dir_templates=(\n",
    "            \"ASVspoof2019_LA_cm_protocols\",\n",
    "            \"{partition_dir}/protocol\",\n",
    "            \"{partition_dir}\",\n",
    "        ),\n",
    "    ),\n",
    "    \"ASVspoof2019_PA\": DatasetSpec(\n",
    "        partition_dir_template=\"ASVspoof2019_PA_{partition}\",\n",
    "        protocol_patterns=(\n",
    "            \"ASVspoof2019.PA.cm.{partition}.trn.txt\",\n",
    "            \"ASVspoof2019.PA.cm.{partition}.trl.txt\",\n",
    "            \"ASVspoof2019.PA.cm.{partition}.txt\",\n",
    "        ),\n",
    "        audio_subdirs=(\"\", \"wav\", \"flac\"),\n",
    "        audio_extensions=(\".wav\", \".flac\"),\n",
    "        protocol_dir_templates=(\n",
    "            \"ASVspoof2019_PA_cm_protocols\",\n",
    "            \"{partition_dir}/protocol\",\n",
    "            \"{partition_dir}\",\n",
    "        ),\n",
    "    ),\n",
    "    \"ASVspoof5\": DatasetSpec(\n",
    "        partition_dir_template=\"ASVspoof5_{partition}\",\n",
    "        protocol_patterns=(\n",
    "            \"ASVspoof5.cm.{partition}.txt\",\n",
    "            \"ASVspoof5.{partition}.cm.txt\",\n",
    "            \"ASVspoof5.{partition}.txt\",\n",
    "        ),\n",
    "        audio_subdirs=(\"\", \"wav\", \"flac\"),\n",
    "        audio_extensions=(\".wav\", \".flac\"),\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ASVExample:\n",
    "    utt_id: str\n",
    "    speaker_id: str\n",
    "    path: str\n",
    "    label: int\n",
    "    system_id: Optional[str] = None\n",
    "    attack_type: Optional[str] = None\n",
    "\n",
    "\n",
    "class ASVspoofLADataset(Dataset):\n",
    "    \"\"\"Dataset PyTorch cho các phiên bản ASVspoof.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_root: str,\n",
    "        partition: str,\n",
    "        feature_extractor: MultiBranchFeatureExtractor,\n",
    "        protocol_file: Optional[str] = None,\n",
    "        sample_rate: int = 16000,\n",
    "        max_duration: float = 6.0,\n",
    "        pad_mode: str = \"repeat\",\n",
    "        preload_waveforms: bool = False,\n",
    "        dataset_variant: str = DEFAULT_DATASET_VARIANT,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if dataset_variant not in DATASET_SPECS:\n",
    "            raise ValueError(\n",
    "                f\"Unsupported dataset_variant {dataset_variant!r}. Available: {list(DATASET_SPECS.keys())}\"\n",
    "            )\n",
    "        self.dataset_variant = dataset_variant\n",
    "        self.dataset_spec = DATASET_SPECS[dataset_variant]\n",
    "\n",
    "        self.data_root = data_root\n",
    "        self.partition = partition\n",
    "        self.sample_rate = sample_rate\n",
    "        self.max_num_samples = int(sample_rate * max_duration)\n",
    "        self.pad_mode = pad_mode\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.preload_waveforms = preload_waveforms\n",
    "\n",
    "        if protocol_file is None:\n",
    "            protocol_file = self._infer_protocol_path()\n",
    "\n",
    "        self.protocol_file = protocol_file\n",
    "        self.examples = self._load_metadata()\n",
    "\n",
    "        if self.preload_waveforms:\n",
    "            self._waveform_cache: Dict[str, Tensor] = {}\n",
    "            for example in self.examples:\n",
    "                waveform, _ = load_audio(example.path, self.sample_rate, normalize=True)\n",
    "                waveform = pad_or_trim(waveform, self.max_num_samples, mode=self.pad_mode)\n",
    "                self._waveform_cache[example.utt_id] = waveform\n",
    "        else:\n",
    "            self._waveform_cache = {}\n",
    "\n",
    "    def _infer_protocol_path(self) -> str:\n",
    "        partition_dir = self.dataset_spec.partition_dir_template.format(partition=self.partition)\n",
    "\n",
    "        protocol_dirs: List[str] = []\n",
    "        for template in self.dataset_spec.protocol_dir_templates:\n",
    "            protocol_dirs.append(\n",
    "                os.path.join(\n",
    "                    self.data_root,\n",
    "                    template.format(partition=self.partition, partition_dir=partition_dir),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        protocol_dirs.extend(\n",
    "            [\n",
    "                os.path.join(self.data_root, partition_dir, \"protocol\"),\n",
    "                os.path.join(self.data_root, partition_dir),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        seen = set()\n",
    "        protocol_dirs = [path for path in protocol_dirs if not (path in seen or seen.add(path))]\n",
    "\n",
    "        candidates: List[str] = []\n",
    "        for proto_dir in protocol_dirs:\n",
    "            for pattern in self.dataset_spec.protocol_patterns:\n",
    "                pattern_path = pattern.format(partition=self.partition)\n",
    "                candidates.append(os.path.join(proto_dir, pattern_path))\n",
    "                if pattern_path.endswith(\".trn.txt\"):\n",
    "                    candidates.append(os.path.join(proto_dir, pattern_path.replace(\".trn\", \"\")))\n",
    "                if pattern_path.endswith(\".trl.txt\"):\n",
    "                    candidates.append(os.path.join(proto_dir, pattern_path.replace(\".trl\", \"\")))\n",
    "\n",
    "        existing = [path for path in candidates if os.path.exists(path)]\n",
    "        if not existing:\n",
    "            raise FileNotFoundError(\n",
    "                f\"Không tìm thấy protocol cho partition={self.partition} trong {', '.join(protocol_dirs)}.\"\n",
    "            )\n",
    "        return existing[0]\n",
    "\n",
    "    def _load_metadata(self) -> List[ASVExample]:\n",
    "        examples: List[ASVExample] = []\n",
    "        with open(self.protocol_file, \"r\", encoding=\"utf-8\") as handle:\n",
    "            reader = csv.reader(handle, delimiter=\" \")\n",
    "            for row in reader:\n",
    "                tokens = [tok for tok in row if tok]\n",
    "                if not tokens:\n",
    "                    continue\n",
    "                if len(tokens) < 3:\n",
    "                    raise ValueError(f\"Không thể parse dòng protocol: {tokens}\")\n",
    "\n",
    "                speaker_id, utt_id = tokens[:2]\n",
    "                label_token = tokens[-1].lower()\n",
    "\n",
    "                middle_tokens = tokens[2:-1]\n",
    "                system_id: Optional[str] = None\n",
    "                attack_type: Optional[str] = None\n",
    "                if middle_tokens:\n",
    "                    system_candidate = middle_tokens[-1]\n",
    "                    if system_candidate != \"-\":\n",
    "                        system_id = system_candidate\n",
    "                    if len(middle_tokens) >= 2:\n",
    "                        attack_candidate = middle_tokens[0]\n",
    "                        if attack_candidate != \"-\":\n",
    "                            attack_type = attack_candidate\n",
    "\n",
    "                if label_token not in LA_LABELS:\n",
    "                    raise ValueError(f\"Nhãn không hợp lệ: {label_token}\")\n",
    "\n",
    "                partition_dir = self.dataset_spec.partition_dir_template.format(partition=self.partition)\n",
    "                audio_path: Optional[str] = None\n",
    "                for subdir in self.dataset_spec.audio_subdirs:\n",
    "                    audio_dir = os.path.join(self.data_root, partition_dir, subdir)\n",
    "                    for ext in self.dataset_spec.audio_extensions:\n",
    "                        candidate = os.path.join(audio_dir, f\"{utt_id}{ext}\")\n",
    "                        if os.path.exists(candidate):\n",
    "                            audio_path = candidate\n",
    "                            break\n",
    "                    if audio_path is not None:\n",
    "                        break\n",
    "                if audio_path is None:\n",
    "                    raise FileNotFoundError(\n",
    "                        f\"Không tìm thấy file audio cho {utt_id} trong {partition_dir}\"\n",
    "                    )\n",
    "\n",
    "                examples.append(\n",
    "                    ASVExample(\n",
    "                        utt_id=utt_id,\n",
    "                        speaker_id=speaker_id,\n",
    "                        path=audio_path,\n",
    "                        label=LA_LABELS[label_token],\n",
    "                        system_id=system_id,\n",
    "                        attack_type=attack_type,\n",
    "                    )\n",
    "                )\n",
    "        return examples\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Dict[str, Any]:\n",
    "        example = self.examples[index]\n",
    "        if example.utt_id in self._waveform_cache:\n",
    "            waveform = self._waveform_cache[example.utt_id]\n",
    "        else:\n",
    "            waveform, _ = load_audio(example.path, self.sample_rate, normalize=True)\n",
    "            waveform = pad_or_trim(waveform, self.max_num_samples, mode=self.pad_mode)\n",
    "\n",
    "        features = self.feature_extractor(waveform)\n",
    "        sample: Dict[str, Any] = {\n",
    "            \"utt_id\": example.utt_id,\n",
    "            \"speaker_id\": example.speaker_id,\n",
    "            \"label\": torch.tensor(example.label, dtype=torch.long),\n",
    "            \"features\": features,\n",
    "        }\n",
    "\n",
    "        metadata = {}\n",
    "        if example.system_id is not None:\n",
    "            metadata[\"system_id\"] = example.system_id\n",
    "        if example.attack_type is not None:\n",
    "            metadata[\"attack_type\"] = example.attack_type\n",
    "        if metadata:\n",
    "            sample[\"meta\"] = metadata\n",
    "        return sample\n",
    "\n",
    "\n",
    "def collate_fn(batch: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    \"\"\"Ghép batch và giữ các nhánh đặc trưng ở dạng riêng biệt.\"\"\"\n",
    "    labels = torch.stack([item[\"label\"] for item in batch], dim=0)\n",
    "\n",
    "    branch_tensors: Dict[str, List[Tensor]] = {}\n",
    "    for item in batch:\n",
    "        features: MultiBranchFeatures = item[\"features\"]\n",
    "        for branch_name, tensor in features.items():\n",
    "            branch_tensors.setdefault(branch_name, []).append(tensor)\n",
    "\n",
    "    stacked_features = {\n",
    "        branch_name: torch.stack(tensors, dim=0)\n",
    "        for branch_name, tensors in branch_tensors.items()\n",
    "    }\n",
    "\n",
    "    output: Dict[str, Any] = {\n",
    "        \"features\": stacked_features,\n",
    "        \"labels\": labels,\n",
    "        \"utt_ids\": [item[\"utt_id\"] for item in batch],\n",
    "        \"speaker_ids\": [item[\"speaker_id\"] for item in batch],\n",
    "    }\n",
    "\n",
    "    metas = [item.get(\"meta\") for item in batch]\n",
    "    if any(meta is not None for meta in metas):\n",
    "        output[\"meta\"] = metas\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PartitionConfig:\n",
    "    partition: str\n",
    "    protocol_file: Optional[str] = None\n",
    "    batch_size: int = 32\n",
    "    shuffle: bool = True\n",
    "    drop_last: bool = False\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataModuleConfig:\n",
    "    data_root: str\n",
    "    sample_rate: int = 16000\n",
    "    max_duration: float = 6.0\n",
    "    pad_mode: str = \"repeat\"\n",
    "    num_workers: int = 4\n",
    "    pin_memory: bool = True\n",
    "    prefetch_factor: int = 2\n",
    "    feature: FeatureConfig = field(default_factory=FeatureConfig)\n",
    "    train: Optional[PartitionConfig] = None\n",
    "    valid: Optional[PartitionConfig] = None\n",
    "    test: Optional[PartitionConfig] = None\n",
    "    preload_waveforms: bool = False\n",
    "    dataset_variant: str = DEFAULT_DATASET_VARIANT\n",
    "\n",
    "\n",
    "class ASVspoofDataModule:\n",
    "    \"\"\"Đóng gói logic tạo DataLoader cho train / validation / test.\"\"\"\n",
    "\n",
    "    def __init__(self, config: DataModuleConfig) -> None:\n",
    "        if config.train is None or config.valid is None:\n",
    "            raise ValueError(\"Cần cấu hình train và valid partitions.\")\n",
    "        self.config = config\n",
    "        self.feature_extractor = MultiBranchFeatureExtractor(config.feature)\n",
    "        self._datasets: Dict[str, ASVspoofLADataset] = {}\n",
    "        self._rng = self._build_generator()\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None) -> None:\n",
    "        if stage in (None, \"fit\"):\n",
    "            self._datasets[\"train\"] = self._build_dataset(self.config.train)\n",
    "            self._datasets[\"valid\"] = self._build_dataset(self.config.valid)\n",
    "        if stage in (None, \"test\") and self.config.test is not None:\n",
    "            self._datasets[\"test\"] = self._build_dataset(self.config.test)\n",
    "\n",
    "    def _build_dataset(self, part_cfg: PartitionConfig) -> ASVspoofLADataset:\n",
    "        return ASVspoofLADataset(\n",
    "            data_root=self.config.data_root,\n",
    "            partition=part_cfg.partition,\n",
    "            protocol_file=part_cfg.protocol_file,\n",
    "            feature_extractor=self.feature_extractor,\n",
    "            sample_rate=self.config.sample_rate,\n",
    "            max_duration=self.config.max_duration,\n",
    "            pad_mode=self.config.pad_mode,\n",
    "            preload_waveforms=self.config.preload_waveforms,\n",
    "            dataset_variant=self.config.dataset_variant,\n",
    "        )\n",
    "\n",
    "    def _build_loader(self, dataset: ASVspoofLADataset, part_cfg: PartitionConfig) -> DataLoader:\n",
    "        loader_kwargs = dict(\n",
    "            dataset=dataset,\n",
    "            batch_size=part_cfg.batch_size,\n",
    "            shuffle=part_cfg.shuffle,\n",
    "            drop_last=part_cfg.drop_last,\n",
    "            num_workers=self.config.num_workers,\n",
    "            pin_memory=self.config.pin_memory,\n",
    "            collate_fn=collate_fn,\n",
    "            generator=self._rng,\n",
    "        )\n",
    "        if self.config.num_workers > 0:\n",
    "            loader_kwargs[\"prefetch_factor\"] = self.config.prefetch_factor\n",
    "        return DataLoader(**loader_kwargs)\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return self._build_loader(self._datasets[\"train\"], self.config.train)\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return self._build_loader(self._datasets[\"valid\"], self.config.valid)\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        if \"test\" not in self._datasets:\n",
    "            raise RuntimeError(\"Chưa cấu hình test dataset.\")\n",
    "        assert self.config.test is not None\n",
    "        return self._build_loader(self._datasets[\"test\"], self.config.test)\n",
    "\n",
    "    def _build_generator(self) -> torch.Generator:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        generator = torch.Generator(device=device)\n",
    "        generator.manual_seed(torch.initial_seed())\n",
    "        return generator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Kiến trúc mô hình đa nhánh\n",
    "Các cell này tương ứng với `src/models/multi_branch_model.py`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def conv2d_block(\n",
    "    in_channels: int,\n",
    "    out_channels: int,\n",
    "    kernel_size: Tuple[int, int] = (3, 3),\n",
    "    stride: Tuple[int, int] = (1, 1),\n",
    "    padding: Tuple[int, int] = (1, 1),\n",
    "    dropout: float = 0.0,\n",
    ") -> nn.Sequential:\n",
    "    layers = [\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True),\n",
    "    ]\n",
    "    if dropout > 0:\n",
    "        layers.append(nn.Dropout2d(dropout))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def conv1d_block(\n",
    "    in_channels: int,\n",
    "    out_channels: int,\n",
    "    kernel_size: int = 3,\n",
    "    stride: int = 1,\n",
    "    padding: int = 1,\n",
    "    dropout: float = 0.0,\n",
    ") -> nn.Sequential:\n",
    "    layers = [\n",
    "        nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "        nn.BatchNorm1d(out_channels),\n",
    "        nn.ReLU(inplace=True),\n",
    "    ]\n",
    "    if dropout > 0:\n",
    "        layers.append(nn.Dropout(dropout))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SpectralBranch(nn.Module):\n",
    "    def __init__(self, in_channels: int = 1, hidden_dim: int = 256) -> None:\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            conv2d_block(in_channels, 32, dropout=0.1),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            conv2d_block(32, 64, dropout=0.15),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            conv2d_block(64, 128, dropout=0.2),\n",
    "            conv2d_block(128, 128, dropout=0.2),\n",
    "        )\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TemporalBranch(nn.Module):\n",
    "    def __init__(self, in_channels: int = 1, hidden_dim: int = 256) -> None:\n",
    "        super().__init__()\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            conv1d_block(in_channels, 32, kernel_size=11, stride=2, padding=5, dropout=0.1),\n",
    "            conv1d_block(32, 64, kernel_size=9, stride=2, padding=4, dropout=0.1),\n",
    "            conv1d_block(64, 128, kernel_size=7, stride=2, padding=3, dropout=0.15),\n",
    "            conv1d_block(128, 128, kernel_size=5, stride=1, padding=2, dropout=0.15),\n",
    "        )\n",
    "        self.temporal_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.conv_stack(x)\n",
    "        x = self.temporal_pool(x)\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CepstralBranch(nn.Module):\n",
    "    def __init__(self, in_channels: int = 1, hidden_dim: int = 256) -> None:\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            conv2d_block(in_channels, 32, kernel_size=(3, 5), padding=(1, 2), dropout=0.1),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            conv2d_block(32, 64, kernel_size=(3, 5), padding=(1, 2), dropout=0.15),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            conv2d_block(64, 128, kernel_size=(3, 3), padding=(1, 1), dropout=0.2),\n",
    "        )\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "class AttentionFusion(nn.Module):\n",
    "    \"\"\"Tầng self-attention đơn giản trên embedding của các nhánh.\"\"\"\n",
    "\n",
    "    def __init__(self, embed_dim: int, attn_dim: int = 128, dropout: float = 0.1) -> None:\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(embed_dim, attn_dim)\n",
    "        self.score = nn.Linear(attn_dim, 1, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, branch_embeddings: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        attn_hidden = torch.tanh(self.proj(branch_embeddings))\n",
    "        scores = self.score(attn_hidden).squeeze(-1)\n",
    "        weights = torch.softmax(scores, dim=-1)\n",
    "        branch_embeddings = self.dropout(branch_embeddings)\n",
    "        fused = torch.sum(branch_embeddings * weights.unsqueeze(-1), dim=1)\n",
    "        return fused, weights\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MultiBranchModelConfig:\n",
    "    embed_dim: int = 256\n",
    "    attn_dim: int = 128\n",
    "    num_classes: int = 2\n",
    "    classifier_hidden: int = 128\n",
    "    dropout: float = 0.3\n",
    "\n",
    "\n",
    "class MultiBranchAttentionModel(nn.Module):\n",
    "    \"\"\"Kiến trúc đa nhánh với attention fusion.\"\"\"\n",
    "\n",
    "    def __init__(self, config: MultiBranchModelConfig) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.branches = nn.ModuleDict(\n",
    "            {\n",
    "                \"spectral\": SpectralBranch(in_channels=1, hidden_dim=config.embed_dim),\n",
    "                \"temporal\": TemporalBranch(in_channels=1, hidden_dim=config.embed_dim),\n",
    "                \"cepstral\": CepstralBranch(in_channels=1, hidden_dim=config.embed_dim),\n",
    "            }\n",
    "        )\n",
    "        self.fusion = AttentionFusion(config.embed_dim, config.attn_dim, dropout=config.dropout)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(config.embed_dim, config.classifier_hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(config.dropout),\n",
    "            nn.Linear(config.classifier_hidden, config.num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, features: Dict[str, Tensor]) -> Dict[str, Tensor]:\n",
    "        branch_outputs = []\n",
    "        attn_order = []\n",
    "        for branch_name, module in self.branches.items():\n",
    "            if branch_name not in features:\n",
    "                raise KeyError(f\"Thiếu nhánh {branch_name} trong input features.\")\n",
    "            branch_out = module(features[branch_name])\n",
    "            branch_outputs.append(branch_out.unsqueeze(1))\n",
    "            attn_order.append(branch_name)\n",
    "\n",
    "        branch_stack = torch.cat(branch_outputs, dim=1)\n",
    "        fused, weights = self.fusion(branch_stack)\n",
    "        logits = self.classifier(fused)\n",
    "        return {\n",
    "            \"logits\": logits,\n",
    "            \"fused\": fused,\n",
    "            \"attention_weights\": weights,\n",
    "            \"branch_embeddings\": branch_stack,\n",
    "            \"branch_order\": attn_order,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hàm đánh giá và metric\n",
    "Tương ứng với `src/utils/metrics.py`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "DEFAULT_TDCF_PARAMS = {\n",
    "    \"P_tar\": 0.9802,\n",
    "    \"P_non\": 0.0091,\n",
    "    \"P_spoof\": 0.0107,\n",
    "    \"C_miss_asv\": 1.0,\n",
    "    \"C_fa_asv\": 10.0,\n",
    "    \"C_miss_cm\": 1.0,\n",
    "    \"C_fa_cm\": 10.0,\n",
    "    \"P_miss_asv\": 0.05,\n",
    "    \"P_fa_asv\": 0.01,\n",
    "    \"P_fa_asv_spoof\": 0.30,\n",
    "}\n",
    "\n",
    "\n",
    "def compute_accuracy(logits: Tensor, labels: Tensor) -> float:\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    correct = (preds == labels).sum().item()\n",
    "    return correct / labels.numel()\n",
    "\n",
    "\n",
    "def compute_eer(scores: Tensor, labels: Tensor) -> float:\n",
    "    \"\"\"Tính Equal Error Rate (EER).\"\"\"\n",
    "    labels_np = labels.detach().cpu().numpy().astype(np.int32)\n",
    "    scores_np = scores.detach().cpu().numpy()\n",
    "\n",
    "    order = np.argsort(scores_np)[::-1]\n",
    "    sorted_labels = labels_np[order]\n",
    "\n",
    "    positives = sorted_labels.sum()\n",
    "    negatives = len(sorted_labels) - positives\n",
    "    if positives == 0 or negatives == 0:\n",
    "        return 0.0\n",
    "\n",
    "    false_accepts = 0\n",
    "    false_rejects = positives\n",
    "    min_gap = 1.0\n",
    "    eer = 1.0\n",
    "\n",
    "    for label in sorted_labels:\n",
    "        if label == 1:\n",
    "            false_rejects -= 1\n",
    "        else:\n",
    "            false_accepts += 1\n",
    "\n",
    "        far = false_accepts / negatives\n",
    "        frr = false_rejects / positives\n",
    "        gap = abs(far - frr)\n",
    "        if gap < min_gap:\n",
    "            min_gap = gap\n",
    "            eer = (far + frr) / 2.0\n",
    "    return float(eer)\n",
    "\n",
    "\n",
    "def compute_tdcf(scores: Tensor, labels: Tensor, params: Optional[Dict[str, float]] = None) -> float:\n",
    "    labels_np = labels.detach().cpu().numpy().astype(np.int32)\n",
    "    scores_np = scores.detach().cpu().numpy()\n",
    "\n",
    "    bona_scores = scores_np[labels_np == 0]\n",
    "    spoof_scores = scores_np[labels_np == 1]\n",
    "    if bona_scores.size == 0 or spoof_scores.size == 0:\n",
    "        return 0.0\n",
    "\n",
    "    params = {**DEFAULT_TDCF_PARAMS, **(params or {})}\n",
    "\n",
    "    c_miss_asv = params[\"C_miss_asv\"]\n",
    "    c_fa_asv = params[\"C_fa_asv\"]\n",
    "    c_miss_cm = params[\"C_miss_cm\"]\n",
    "    c_fa_cm = params[\"C_fa_cm\"]\n",
    "    p_tar = params[\"P_tar\"]\n",
    "    p_non = params[\"P_non\"]\n",
    "    p_spoof = params[\"P_spoof\"]\n",
    "    p_miss_asv = params[\"P_miss_asv\"]\n",
    "    p_fa_asv = params[\"P_fa_asv\"]\n",
    "    p_fa_asv_spoof = params[\"P_fa_asv_spoof\"]\n",
    "\n",
    "    thresholds = np.concatenate(([-np.inf], np.sort(scores_np), [np.inf]))\n",
    "    c_default = min(c_miss_asv * p_tar, c_fa_asv * p_non)\n",
    "    if c_default <= 0:\n",
    "        c_default = 1.0\n",
    "\n",
    "    asv_term = c_miss_asv * p_tar * p_miss_asv + c_fa_asv * p_non * p_fa_asv\n",
    "\n",
    "    tdcf_values = []\n",
    "    for tau in thresholds:\n",
    "        p_miss_cm = float(np.mean(bona_scores >= tau))\n",
    "        p_fa_cm = float(np.mean(spoof_scores < tau))\n",
    "        cm_term = (\n",
    "            c_miss_cm * p_tar * (1.0 - p_miss_asv) * p_miss_cm\n",
    "            + c_fa_cm * p_spoof * (1.0 - p_fa_asv_spoof) * p_fa_cm\n",
    "        )\n",
    "        tdcf_values.append((asv_term + cm_term) / c_default)\n",
    "\n",
    "    return float(np.min(tdcf_values))\n",
    "\n",
    "\n",
    "def aggregate_metrics(logits: Tensor, labels: Tensor) -> Dict[str, float]:\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    spoof_scores = probs[:, 1]\n",
    "    accuracy = compute_accuracy(logits, labels)\n",
    "    eer = compute_eer(spoof_scores, labels)\n",
    "    tdcf = compute_tdcf(spoof_scores, labels)\n",
    "    return {\"accuracy\": accuracy, \"eer\": eer, \"t_dcf\": tdcf}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Vòng lặp huấn luyện\n",
    "Các cell dưới đây tương ứng với `src/training/engine.py`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class OptimizerConfig:\n",
    "    lr: float = 1e-4\n",
    "    weight_decay: float = 1e-5\n",
    "    betas: tuple = (0.9, 0.98)\n",
    "    eps: float = 1e-8\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SchedulerConfig:\n",
    "    use_cosine: bool = True\n",
    "    min_lr: float = 1e-6\n",
    "    t_max: Optional[int] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    epochs: int = 50\n",
    "    device: Optional[str] = None\n",
    "    log_interval: int = 20\n",
    "    grad_clip: float = 5.0\n",
    "    mixed_precision: bool = True\n",
    "    checkpoint_dir: str = \"checkpoints\"\n",
    "    best_metric: str = \"eer\"\n",
    "    patience: int = 10\n",
    "    resume_from: Optional[str] = None\n",
    "    save_every: int = 0\n",
    "    history: List[Dict[str, float]] = field(default_factory=list)\n",
    "    evaluate_on_test: bool = False\n",
    "    model_output_path: Optional[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        train_config: TrainingConfig,\n",
    "        optim_config: OptimizerConfig,\n",
    "        scheduler_config: SchedulerConfig,\n",
    "    ) -> None:\n",
    "        self.model = model\n",
    "        self.train_config = train_config\n",
    "        self.optim_config = optim_config\n",
    "        self.scheduler_config = scheduler_config\n",
    "\n",
    "        device_str = (\n",
    "            train_config.device\n",
    "            if train_config.device is not None\n",
    "            else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        )\n",
    "        self.device = torch.device(device_str)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.scaler = torch.cuda.amp.GradScaler(\n",
    "            enabled=(self.device.type == \"cuda\" and train_config.mixed_precision)\n",
    "        )\n",
    "        self.best_metric_value: Optional[float] = None\n",
    "        self.best_epoch: Optional[int] = None\n",
    "\n",
    "    def fit(self, datamodule: ASVspoofDataModule) -> Dict[str, List[Dict[str, float]]]:\n",
    "        datamodule.setup(stage=\"fit\")\n",
    "        train_loader = datamodule.train_dataloader()\n",
    "        valid_loader = datamodule.val_dataloader()\n",
    "\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=self.optim_config.lr,\n",
    "            weight_decay=self.optim_config.weight_decay,\n",
    "            betas=self.optim_config.betas,\n",
    "            eps=self.optim_config.eps,\n",
    "        )\n",
    "        scheduler = self._build_scheduler(optimizer)\n",
    "        os.makedirs(self.train_config.checkpoint_dir, exist_ok=True)\n",
    "\n",
    "        history = {\"train\": [], \"valid\": []}\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(1, self.train_config.epochs + 1):\n",
    "            train_metrics = self._run_epoch(\n",
    "                loader=train_loader,\n",
    "                optimizer=optimizer,\n",
    "                scheduler=scheduler,\n",
    "                epoch=epoch,\n",
    "                train=True,\n",
    "            )\n",
    "            valid_metrics = self._run_epoch(\n",
    "                loader=valid_loader,\n",
    "                optimizer=None,\n",
    "                scheduler=None,\n",
    "                epoch=epoch,\n",
    "                train=False,\n",
    "            )\n",
    "\n",
    "            history[\"train\"].append(train_metrics)\n",
    "            history[\"valid\"].append(valid_metrics)\n",
    "            self.train_config.history.append(\n",
    "                {\"epoch\": epoch, **train_metrics, **{f\"val_{k}\": v for k, v in valid_metrics.items()}}\n",
    "            )\n",
    "\n",
    "            self._log_epoch_metrics(epoch, train_metrics, valid_metrics)\n",
    "\n",
    "            current_metric = valid_metrics.get(self.train_config.best_metric)\n",
    "            if current_metric is None:\n",
    "                raise KeyError(\n",
    "                    f\"Không tìm thấy metric {self.train_config.best_metric} trong valid metrics: {valid_metrics}\"\n",
    "                )\n",
    "\n",
    "            if self._is_better(current_metric):\n",
    "                self.best_metric_value = current_metric\n",
    "                self.best_epoch = epoch\n",
    "                patience_counter = 0\n",
    "                self._save_checkpoint(optimizer, epoch, best=True)\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            if self.train_config.save_every > 0 and epoch % self.train_config.save_every == 0:\n",
    "                self._save_checkpoint(optimizer, epoch, best=False)\n",
    "\n",
    "            if scheduler is not None and getattr(scheduler, \"step\", None) is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "            if patience_counter >= self.train_config.patience:\n",
    "                print(f\"[Trainer] Early stopping ở epoch {epoch}.\")\n",
    "                break\n",
    "\n",
    "        return history\n",
    "\n",
    "    def evaluate(self, datamodule: ASVspoofDataModule) -> Dict[str, float]:\n",
    "        datamodule.setup(stage=\"test\")\n",
    "        test_loader = datamodule.test_dataloader()\n",
    "        metrics = self._run_epoch(loader=test_loader, optimizer=None, scheduler=None, epoch=0, train=False)\n",
    "        return metrics\n",
    "\n",
    "    def _run_epoch(\n",
    "        self,\n",
    "        loader: DataLoader,\n",
    "        optimizer: Optional[torch.optim.Optimizer],\n",
    "        scheduler: Optional[torch.optim.lr_scheduler._LRScheduler],\n",
    "        epoch: int,\n",
    "        train: bool,\n",
    "    ) -> Dict[str, float]:\n",
    "        if train:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "\n",
    "        total_loss = 0.0\n",
    "        total_samples = 0\n",
    "        all_logits: List[Tensor] = []\n",
    "        all_labels: List[Tensor] = []\n",
    "\n",
    "        for step, batch in enumerate(loader, start=1):\n",
    "            features = {\n",
    "                name: tensor.to(self.device, non_blocking=True)\n",
    "                for name, tensor in batch[\"features\"].items()\n",
    "            }\n",
    "            labels = batch[\"labels\"].to(self.device, non_blocking=True)\n",
    "            batch_size = labels.size(0)\n",
    "\n",
    "            with torch.set_grad_enabled(train):\n",
    "                with torch.cuda.amp.autocast(enabled=self.scaler.is_enabled()):\n",
    "                    outputs = self.model(features)\n",
    "                    logits = outputs[\"logits\"]\n",
    "                    loss = self.criterion(logits, labels)\n",
    "\n",
    "                if train:\n",
    "                    assert optimizer is not None\n",
    "                    self.scaler.scale(loss).backward()\n",
    "                    if self.train_config.grad_clip > 0:\n",
    "                        self.scaler.unscale_(optimizer)\n",
    "                        torch.nn.utils.clip_grad_norm_(\n",
    "                            self.model.parameters(), self.train_config.grad_clip\n",
    "                        )\n",
    "                    self.scaler.step(optimizer)\n",
    "                    self.scaler.update()\n",
    "                    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            total_loss += loss.item() * batch_size\n",
    "            total_samples += batch_size\n",
    "            all_logits.append(logits.detach().cpu())\n",
    "            all_labels.append(labels.detach().cpu())\n",
    "\n",
    "            if train and self.train_config.log_interval and step % self.train_config.log_interval == 0:\n",
    "                current_loss = total_loss / total_samples\n",
    "                lr = optimizer.param_groups[0]['lr'] if optimizer is not None else 0.0\n",
    "                print(\n",
    "                    f\"[Epoch {epoch}] Step {step}/{len(loader)} \"\n",
    "                    f\"Loss: {current_loss:.4f} LR: {lr:.2e}\"\n",
    "                )\n",
    "\n",
    "        avg_loss = total_loss / max(total_samples, 1)\n",
    "        logits_tensor = torch.cat(all_logits, dim=0)\n",
    "        labels_tensor = torch.cat(all_labels, dim=0)\n",
    "        metrics = aggregate_metrics(logits_tensor, labels_tensor)\n",
    "        metrics[\"loss\"] = avg_loss\n",
    "        return metrics\n",
    "\n",
    "    def _is_better(self, value: float) -> bool:\n",
    "        if self.best_metric_value is None:\n",
    "            return True\n",
    "        if self.train_config.best_metric in {\"loss\", \"eer\"}:\n",
    "            return value < self.best_metric_value\n",
    "        return value > self.best_metric_value\n",
    "\n",
    "    def _save_checkpoint(self, optimizer: Optional[torch.optim.Optimizer], epoch: int, best: bool) -> None:\n",
    "        state = {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": self.model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict() if optimizer is not None else None,\n",
    "            \"best_metric\": self.best_metric_value,\n",
    "            \"best_epoch\": self.best_epoch,\n",
    "        }\n",
    "        suffix = \"best\" if best else f\"epoch_{epoch:03d}\"\n",
    "        path = os.path.join(self.train_config.checkpoint_dir, f\"checkpoint_{suffix}.pt\")\n",
    "        torch.save(state, path)\n",
    "        tag = \"BEST\" if best else \"SNAPSHOT\"\n",
    "        print(f\"[Trainer] Đã lưu checkpoint ({tag}) tại {path}\")\n",
    "\n",
    "    def _build_scheduler(self, optimizer: torch.optim.Optimizer):\n",
    "        if not self.scheduler_config.use_cosine:\n",
    "            return None\n",
    "        t_max = (\n",
    "            self.scheduler_config.t_max\n",
    "            if self.scheduler_config.t_max is not None\n",
    "            else self.train_config.epochs\n",
    "        )\n",
    "        return torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=t_max,\n",
    "            eta_min=self.scheduler_config.min_lr,\n",
    "        )\n",
    "\n",
    "    def load_checkpoint(self, path: str) -> None:\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(f\"Không tìm thấy checkpoint: {path}\")\n",
    "        state = torch.load(path, map_location=self.device)\n",
    "        model_state = state.get(\"model_state_dict\", state)\n",
    "        self.model.load_state_dict(model_state)\n",
    "        self.model.to(self.device)\n",
    "        self.best_metric_value = state.get(\"best_metric\", self.best_metric_value)\n",
    "        self.best_epoch = state.get(\"best_epoch\", self.best_epoch)\n",
    "        print(f\"[Trainer] Đã tải checkpoint từ {path}\")\n",
    "\n",
    "    def _log_epoch_metrics(\n",
    "        self,\n",
    "        epoch: int,\n",
    "        train_metrics: Dict[str, float],\n",
    "        valid_metrics: Dict[str, float],\n",
    "    ) -> None:\n",
    "        def _format(metrics: Dict[str, float]) -> str:\n",
    "            ordered = sorted(metrics.items())\n",
    "            return \" \".join(f\"{name}: {value:.4f}\" for name, value in ordered)\n",
    "\n",
    "        print(f\"[Epoch {epoch}] Train metrics -> {_format(train_metrics)}\")\n",
    "        print(f\"[Epoch {epoch}] Valid metrics -> {_format(valid_metrics)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Hàm tiện ích đọc YAML và xây cấu hình\n",
    "Phần này tương đương `train.py` trong dự án gốc."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_yaml_config(path: str) -> Dict[str, Any]:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as handle:\n",
    "        return yaml.safe_load(handle)\n",
    "\n",
    "\n",
    "def build_feature_config(cfg: Dict[str, Any]) -> FeatureConfig:\n",
    "    base = FeatureConfig()\n",
    "    spectral = {**base.spectral, **cfg.get(\"spectral\", {})}\n",
    "    temporal = {**base.temporal, **cfg.get(\"temporal\", {})}\n",
    "    cepstral = {**base.cepstral, **cfg.get(\"cepstral\", {})}\n",
    "    return FeatureConfig(\n",
    "        sample_rate=cfg.get(\"sample_rate\", base.sample_rate),\n",
    "        spectral=spectral,\n",
    "        temporal=temporal,\n",
    "        cepstral=cepstral,\n",
    "    )\n",
    "\n",
    "\n",
    "def build_partition_config(cfg: Dict[str, Any]) -> PartitionConfig:\n",
    "    return PartitionConfig(\n",
    "        partition=cfg[\"partition\"],\n",
    "        protocol_file=cfg.get(\"protocol_file\"),\n",
    "        batch_size=cfg.get(\"batch_size\", 32),\n",
    "        shuffle=cfg.get(\"shuffle\", True),\n",
    "        drop_last=cfg.get(\"drop_last\", False),\n",
    "    )\n",
    "\n",
    "\n",
    "def build_data_module_config(cfg: Dict[str, Any]) -> DataModuleConfig:\n",
    "    feature_cfg = build_feature_config(cfg.get(\"feature\", {}))\n",
    "    train_cfg = build_partition_config(cfg[\"train\"])\n",
    "    valid_cfg = build_partition_config(cfg[\"valid\"])\n",
    "    test_cfg = (\n",
    "        build_partition_config(cfg[\"test\"]) if cfg.get(\"test\") is not None else None\n",
    "    )\n",
    "    return DataModuleConfig(\n",
    "        data_root=cfg[\"data_root\"],\n",
    "        sample_rate=cfg.get(\"sample_rate\", feature_cfg.sample_rate),\n",
    "        max_duration=cfg.get(\"max_duration\", 6.0),\n",
    "        pad_mode=cfg.get(\"pad_mode\", \"repeat\"),\n",
    "        num_workers=cfg.get(\"num_workers\", 4),\n",
    "        pin_memory=cfg.get(\"pin_memory\", True),\n",
    "        prefetch_factor=cfg.get(\"prefetch_factor\", 2),\n",
    "        feature=feature_cfg,\n",
    "        train=train_cfg,\n",
    "        valid=valid_cfg,\n",
    "        test=test_cfg,\n",
    "        preload_waveforms=cfg.get(\"preload_waveforms\", False),\n",
    "        dataset_variant=cfg.get(\"dataset_variant\", DEFAULT_DATASET_VARIANT),\n",
    "    )\n",
    "\n",
    "\n",
    "def build_model_config(cfg: Dict[str, Any]) -> MultiBranchModelConfig:\n",
    "    base = MultiBranchModelConfig()\n",
    "    return MultiBranchModelConfig(\n",
    "        embed_dim=cfg.get(\"embed_dim\", base.embed_dim),\n",
    "        attn_dim=cfg.get(\"attn_dim\", base.attn_dim),\n",
    "        num_classes=cfg.get(\"num_classes\", base.num_classes),\n",
    "        classifier_hidden=cfg.get(\"classifier_hidden\", base.classifier_hidden),\n",
    "        dropout=cfg.get(\"dropout\", base.dropout),\n",
    "    )\n",
    "\n",
    "\n",
    "def build_training_config(cfg: Dict[str, Any]) -> TrainingConfig:\n",
    "    base = TrainingConfig()\n",
    "    return TrainingConfig(\n",
    "        epochs=cfg.get(\"epochs\", base.epochs),\n",
    "        device=cfg.get(\"device\", base.device),\n",
    "        log_interval=cfg.get(\"log_interval\", base.log_interval),\n",
    "        grad_clip=cfg.get(\"grad_clip\", base.grad_clip),\n",
    "        mixed_precision=cfg.get(\"mixed_precision\", base.mixed_precision),\n",
    "        checkpoint_dir=cfg.get(\"checkpoint_dir\", base.checkpoint_dir),\n",
    "        best_metric=cfg.get(\"best_metric\", base.best_metric),\n",
    "        patience=cfg.get(\"patience\", base.patience),\n",
    "        resume_from=cfg.get(\"resume_from\", base.resume_from),\n",
    "        save_every=cfg.get(\"save_every\", base.save_every),\n",
    "        evaluate_on_test=cfg.get(\"evaluate_on_test\", base.evaluate_on_test),\n",
    "        model_output_path=cfg.get(\"model_output_path\", base.model_output_path),\n",
    "    )\n",
    "\n",
    "\n",
    "def build_optimizer_config(cfg: Dict[str, Any]) -> OptimizerConfig:\n",
    "    base = OptimizerConfig()\n",
    "    return OptimizerConfig(\n",
    "        lr=cfg.get(\"lr\", base.lr),\n",
    "        weight_decay=cfg.get(\"weight_decay\", base.weight_decay),\n",
    "        betas=tuple(cfg.get(\"betas\", base.betas)),\n",
    "        eps=cfg.get(\"eps\", base.eps),\n",
    "    )\n",
    "\n",
    "\n",
    "def build_scheduler_config(cfg: Dict[str, Any], total_epochs: int) -> SchedulerConfig:\n",
    "    base = SchedulerConfig()\n",
    "    use_cosine = cfg.get(\"use_cosine\", base.use_cosine)\n",
    "    min_lr = cfg.get(\"min_lr\", base.min_lr)\n",
    "    t_max = cfg.get(\"t_max\", total_epochs if base.t_max is None else base.t_max)\n",
    "    return SchedulerConfig(use_cosine=use_cosine, min_lr=min_lr, t_max=t_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Hàm chạy huấn luyện chính\n",
    "Cell này gom tất cả lại tương đương hàm `main()` trong `train.py`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_training_curves(history: Dict[str, List[Dict[str, float]]], output_path: str) -> None:\n",
    "    if not history or not history.get(\"train\"):\n",
    "        return\n",
    "\n",
    "    output_dir = os.path.dirname(output_path) or \".\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    train_history = history.get(\"train\", [])\n",
    "    valid_history = history.get(\"valid\", [])\n",
    "    if not train_history:\n",
    "        return\n",
    "\n",
    "    metrics = list(train_history[0].keys())\n",
    "    epochs = list(range(1, len(train_history) + 1))\n",
    "    num_metrics = len(metrics)\n",
    "    fig, axes = plt.subplots(num_metrics, 1, figsize=(8, 4 * num_metrics), sharex=True)\n",
    "    if num_metrics == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, metric in zip(axes, metrics):\n",
    "        train_values = [record.get(metric) for record in train_history]\n",
    "        val_values = [record.get(metric) for record in valid_history]\n",
    "        ax.plot(epochs, train_values, label=\"Train\", marker=\"o\")\n",
    "        if valid_history:\n",
    "            ax.plot(epochs, val_values, label=\"Validation\", marker=\"s\")\n",
    "        ax.set_ylabel(metric.replace(\"_\", \" \").title())\n",
    "        ax.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "        ax.legend()\n",
    "\n",
    "    axes[-1].set_xlabel(\"Epoch\")\n",
    "    fig.suptitle(\"Training Curves\", fontsize=14)\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "    fig.savefig(output_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def export_trained_model(trainer: Trainer, output_path: str) -> None:\n",
    "    output_dir = os.path.dirname(output_path) or \".\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    torch.save(trainer.model.state_dict(), output_path)\n",
    "    print(f\"[Trainer] Đã lưu trọng số mô hình tại {output_path}\")\n",
    "\n",
    "\n",
    "def prepare_inference_from_config(\n",
    "    config: Dict[str, Any],\n",
    "    checkpoint_path: str,\n",
    "    device: Optional[str] = None,\n",
    "):\n",
    "    data_cfg = build_data_module_config(config[\"data\"])\n",
    "    model_cfg = build_model_config(config.get(\"model\", {}))\n",
    "\n",
    "    model = MultiBranchAttentionModel(model_cfg)\n",
    "    device_str = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device_obj = torch.device(device_str)\n",
    "    model.to(device_obj)\n",
    "\n",
    "    state = torch.load(checkpoint_path, map_location=device_obj)\n",
    "    model_state = state.get(\"model_state_dict\", state)\n",
    "    model.load_state_dict(model_state)\n",
    "    model.eval()\n",
    "\n",
    "    feature_extractor = MultiBranchFeatureExtractor(data_cfg.feature)\n",
    "    return model, feature_extractor, data_cfg, device_obj\n",
    "\n",
    "\n",
    "def infer_audio_from_checkpoint(\n",
    "    audio_path: str,\n",
    "    config: Dict[str, Any],\n",
    "    checkpoint_path: str,\n",
    "    device: Optional[str] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    model, feature_extractor, data_cfg, device_obj = prepare_inference_from_config(\n",
    "        config, checkpoint_path, device=device\n",
    "    )\n",
    "    waveform, _ = load_audio(audio_path, data_cfg.sample_rate, normalize=True)\n",
    "    max_samples = int(data_cfg.sample_rate * data_cfg.max_duration)\n",
    "    waveform = pad_or_trim(waveform, max_samples, mode=data_cfg.pad_mode)\n",
    "\n",
    "    features = feature_extractor(waveform)\n",
    "    batched_features = {\n",
    "        name: tensor.unsqueeze(0).to(device_obj, non_blocking=True)\n",
    "        for name, tensor in features.items()\n",
    "    }\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(batched_features)\n",
    "        logits = outputs[\"logits\"]\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "\n",
    "    spoof_score = float(probs[0, 1].item())\n",
    "    prediction_idx = int(torch.argmax(probs, dim=-1).item())\n",
    "    prediction_label = \"spoof\" if prediction_idx == 1 else \"bonafide\"\n",
    "    return {\n",
    "        \"probabilities\": probs.squeeze(0).cpu().tolist(),\n",
    "        \"spoof_score\": spoof_score,\n",
    "        \"prediction_index\": prediction_idx,\n",
    "        \"prediction_label\": prediction_label,\n",
    "    }\n",
    "\n",
    "\n",
    "def run_training_from_config(config: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    data_cfg = build_data_module_config(config[\"data\"])\n",
    "    model_cfg = build_model_config(config.get(\"model\", {}))\n",
    "    training_cfg = build_training_config(config.get(\"training\", {}))\n",
    "    optimizer_cfg = build_optimizer_config(config.get(\"optimizer\", {}))\n",
    "    scheduler_cfg = build_scheduler_config(\n",
    "        config.get(\"scheduler\", {}),\n",
    "        total_epochs=training_cfg.epochs,\n",
    "    )\n",
    "\n",
    "    datamodule = ASVspoofDataModule(data_cfg)\n",
    "    model = MultiBranchAttentionModel(model_cfg)\n",
    "    trainer = Trainer(model, training_cfg, optimizer_cfg, scheduler_cfg)\n",
    "\n",
    "    history = trainer.fit(datamodule)\n",
    "\n",
    "    plot_path = os.path.join(training_cfg.checkpoint_dir, \"training_curves.png\")\n",
    "    plot_training_curves(history, plot_path)\n",
    "\n",
    "    best_checkpoint = os.path.join(training_cfg.checkpoint_dir, \"checkpoint_best.pt\")\n",
    "    if os.path.exists(best_checkpoint):\n",
    "        trainer.load_checkpoint(best_checkpoint)\n",
    "    else:\n",
    "        print(\n",
    "            f\"[Trainer] Không tìm thấy checkpoint tốt nhất tại {best_checkpoint}. \"\n",
    "            \"Giữ nguyên trọng số cuối cùng.\"\n",
    "        )\n",
    "\n",
    "    model_path = training_cfg.model_output_path or os.path.join(\n",
    "        training_cfg.checkpoint_dir, \"multibranch_model.pt\"\n",
    "    )\n",
    "    export_trained_model(trainer, model_path)\n",
    "\n",
    "    results = {\n",
    "        \"history\": history,\n",
    "        \"best_metric\": trainer.best_metric_value,\n",
    "        \"best_epoch\": trainer.best_epoch,\n",
    "        \"training_plot\": plot_path,\n",
    "        \"model_path\": model_path,\n",
    "        \"best_checkpoint\": best_checkpoint if os.path.exists(best_checkpoint) else None,\n",
    "    }\n",
    "\n",
    "    if training_cfg.evaluate_on_test and data_cfg.test is not None:\n",
    "        test_metrics = trainer.evaluate(datamodule)\n",
    "        results[\"test_metrics\"] = test_metrics\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Ví dụ cấu hình\n",
    "Bạn có thể chỉnh sửa trực tiếp dictionary bên dưới hoặc đọc YAML bằng `load_yaml_config`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "example_config = yaml.safe_load(\"\"\"data:\n",
    "  data_root: \"/kaggle/input/asvpoof-2019-dataset/LA/LA\"\n",
    "  sample_rate: 16000\n",
    "  max_duration: 6.0\n",
    "  pad_mode: \"repeat\"\n",
    "  num_workers: 4\n",
    "  pin_memory: true\n",
    "  prefetch_factor: 2\n",
    "  preload_waveforms: false\n",
    "  dataset_variant: \"ASVspoof2019_LA\"\n",
    "  feature:\n",
    "    spectral:\n",
    "      n_mels: 128\n",
    "      n_fft: 1024\n",
    "      hop_length: 256\n",
    "    temporal:\n",
    "      emphasis: true\n",
    "      highpass_cutoff: 20.0\n",
    "    cepstral:\n",
    "      n_bins: 96\n",
    "      bins_per_octave: 12\n",
    "  train:\n",
    "    partition: \"train\"\n",
    "    protocol_file: \"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt\"\n",
    "    batch_size: 16\n",
    "    shuffle: true\n",
    "    drop_last: true\n",
    "  valid:\n",
    "    partition: \"dev\"\n",
    "    protocol_file: \"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt\"\n",
    "    batch_size: 16\n",
    "    shuffle: false\n",
    "    drop_last: false\n",
    "  test: null\n",
    "model:\n",
    "  embed_dim: 256\n",
    "  attn_dim: 128\n",
    "  classifier_hidden: 128\n",
    "  dropout: 0.3\n",
    "training:\n",
    "  epochs: 50\n",
    "  device: \"cuda\"\n",
    "  log_interval: 20\n",
    "  grad_clip: 5.0\n",
    "  mixed_precision: true\n",
    "  checkpoint_dir: \"checkpoints\"\n",
    "  best_metric: \"eer\"\n",
    "  patience: 8\n",
    "  save_every: 0\n",
    "  evaluate_on_test: false\n",
    "  model_output_path: null\n",
    "optimizer:\n",
    "  lr: 0.0002\n",
    "  weight_decay: 0.00001\n",
    "  betas: [0.9, 0.98]\n",
    "scheduler:\n",
    "  use_cosine: true\n",
    "  min_lr: 0.000001\n",
    "\"\"\")\n",
    "example_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Khám phá dữ liệu với cấu hình hiện tại\n",
    "Chạy các cell sau sau khi bạn đã cập nhật `example_config` (hoặc cấu hình của riêng bạn) để rà soát nhanh cấu trúc thư mục, file protocol và nội dung audio.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from itertools import islice\n",
    "\n",
    "if \"example_config\" not in globals():\n",
    "    raise RuntimeError(\"Vui lòng chạy cell cấu hình ví dụ (mục 10) trước khi khám phá dữ liệu.\")\n",
    "\n",
    "data_cfg = example_config[\"data\"]\n",
    "data_root = Path(data_cfg[\"data_root\"]).expanduser()\n",
    "if not data_root.exists():\n",
    "    raise FileNotFoundError(f\"Không tìm thấy thư mục dữ liệu: {data_root}\")\n",
    "\n",
    "variant_prefix = data_cfg.get(\"dataset_variant\", \"ASVspoof2019_LA\")\n",
    "\n",
    "def resolve_partition_dir(split_key: str) -> Path:\n",
    "    partition_cfg = data_cfg[split_key]\n",
    "    partition_name = partition_cfg.get(\"partition\", split_key)\n",
    "    custom_dir = partition_cfg.get(\"custom_dir\")\n",
    "    if custom_dir is not None:\n",
    "        return data_root / custom_dir\n",
    "    if partition_name.startswith(variant_prefix):\n",
    "        return data_root / partition_name\n",
    "    return data_root / f\"{variant_prefix}_{partition_name}\"\n",
    "\n",
    "for split_key in (\"train\", \"valid\", \"test\"):\n",
    "    if split_key not in data_cfg or data_cfg[split_key] is None:\n",
    "        continue\n",
    "    partition_dir = resolve_partition_dir(split_key)\n",
    "    print(f\"[{split_key.upper()}] {partition_dir}\")\n",
    "    if not partition_dir.exists():\n",
    "        print(\"  -> Không tìm thấy thư mục này. Kiểm tra lại đường dẫn hoặc giải nén dữ liệu.\")\n",
    "        continue\n",
    "    flac_dir = partition_dir / \"flac\"\n",
    "    protocol_dir = partition_dir / \"protocol\"\n",
    "    num_audio = sum(1 for _ in flac_dir.glob(\"*.flac\")) if flac_dir.exists() else 0\n",
    "    sample_files = list(islice(flac_dir.glob(\"*.flac\"), 5)) if flac_dir.exists() else []\n",
    "    print(f\"  Số file âm thanh: {num_audio:,}\")\n",
    "    if sample_files:\n",
    "        examples = ', '.join(path.name for path in sample_files)\n",
    "        print(f\"  Ví dụ file: {examples}\")\n",
    "    protocol_files = sorted(protocol_dir.glob(\"*.txt\")) if protocol_dir.exists() else []\n",
    "    if protocol_files:\n",
    "        print(\"  Protocol:\")\n",
    "        for proto in protocol_files[:2]:\n",
    "            print(f\"    - {proto.name}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "train_dir = resolve_partition_dir(\"train\")\n",
    "protocol_cfg = data_cfg[\"train\"].get(\"protocol_file\")\n",
    "if protocol_cfg:\n",
    "    protocol_path = Path(protocol_cfg)\n",
    "    if not protocol_path.is_absolute():\n",
    "        protocol_path = train_dir / \"protocol\" / protocol_cfg\n",
    "else:\n",
    "    protocol_candidates = sorted((train_dir / \"protocol\").glob(\"*.txt\"))\n",
    "    protocol_path = protocol_candidates[0] if protocol_candidates else None\n",
    "\n",
    "if not protocol_path or not protocol_path.exists():\n",
    "    raise FileNotFoundError(\"Không tìm thấy file protocol cho tập train.\")\n",
    "\n",
    "protocol_cols = [\"speaker_id\", \"utt_id\", \"source\", \"attack_id\", \"label\"]\n",
    "protocol_df = pd.read_csv(\n",
    "    protocol_path,\n",
    "    sep=\" \",\n",
    "    header=None,\n",
    "    names=protocol_cols,\n",
    ")\n",
    "\n",
    "display(protocol_df.head())\n",
    "print(\"\\nSố lượng mẫu theo nhãn:\")\n",
    "display(protocol_df[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "sample_row = protocol_df.sample(1, random_state=0) if len(protocol_df) > 1 else protocol_df\n",
    "sample_row = sample_row.iloc[0]\n",
    "audio_path = train_dir / \"flac\" / f\"{sample_row['utt_id']}.flac\"\n",
    "if not audio_path.exists():\n",
    "    raise FileNotFoundError(f\"Không tìm thấy file audio: {audio_path}\")\n",
    "\n",
    "target_sr = data_cfg.get(\"sample_rate\", 16000)\n",
    "waveform, sr = librosa.load(audio_path, sr=target_sr)\n",
    "duration = waveform.shape[0] / sr\n",
    "print(f\"Đang xem: {sample_row['utt_id']} ({sample_row['label']}) - {duration:.2f}s @ {sr} Hz\")\n",
    "\n",
    "display(Audio(waveform, rate=sr))\n",
    "\n",
    "spectral_cfg = data_cfg.get(\"feature\", {}).get(\"spectral\", {})\n",
    "n_fft = spectral_cfg.get(\"n_fft\", 1024)\n",
    "hop_length = spectral_cfg.get(\"hop_length\", 256)\n",
    "n_mels = spectral_cfg.get(\"n_mels\", 128)\n",
    "mel_spec = librosa.feature.melspectrogram(\n",
    "    y=waveform, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels\n",
    ")\n",
    "mel_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 6), sharex=False)\n",
    "time_axis = np.linspace(0, duration, num=waveform.shape[0])\n",
    "axes[0].plot(time_axis, waveform)\n",
    "axes[0].set_title(\"Waveform\")\n",
    "axes[0].set_xlabel(\"Thời gian (s)\")\n",
    "axes[0].set_ylabel(\"Biên độ\")\n",
    "axes[0].grid(True, linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "img = librosa.display.specshow(\n",
    "    mel_db,\n",
    "    x_axis=\"time\",\n",
    "    y_axis=\"mel\",\n",
    "    sr=sr,\n",
    "    hop_length=hop_length,\n",
    "    cmap=\"magma\",\n",
    "    ax=axes[1],\n",
    ")\n",
    "axes[1].set_title(\"Mel-spectrogram (dB)\")\n",
    "fig.colorbar(img, ax=axes[1], format=\"%.0f dB\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Thực thi huấn luyện (tùy chọn)\n",
    "Chỉ chạy cell này khi bạn đã mount đúng dữ liệu. Nếu muốn đọc từ file YAML, dùng `config = load_yaml_config(path)`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Ví dụ:\n",
    "# config = load_yaml_config(\"/kaggle/input/asvspoof-configs/asvspoof_multibranch.yaml\")\n",
    "# results = run_training_from_config(config)\n",
    "# results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1 Theo dõi lịch sử huấn luyện\n",
    "Sau khi chạy cell huấn luyện ở trên, bạn có thể sử dụng đoạn mã dưới đây để xem bảng metric theo từng epoch và hiển thị biểu đồ đường cong huấn luyện đã lưu.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from IPython.display import Image, display\n",
    "\n",
    "if \"results\" not in globals():\n",
    "    raise RuntimeError(\"Chưa tìm thấy biến `results`. Hãy chạy hàm huấn luyện trước khi tổng hợp lịch sử.\")\n",
    "\n",
    "history = results.get(\"history\", {})\n",
    "train_history = history.get(\"train\", [])\n",
    "valid_history = history.get(\"valid\", [])\n",
    "\n",
    "if not train_history:\n",
    "    print(\"Lịch sử huấn luyện trống.\")\n",
    "else:\n",
    "    rows = []\n",
    "    for epoch_idx, (train_metrics, valid_metrics) in enumerate(zip(train_history, valid_history), start=1):\n",
    "        row = {\"epoch\": epoch_idx, **train_metrics}\n",
    "        row.update({f\"val_{name}\": value for name, value in valid_metrics.items()})\n",
    "        rows.append(row)\n",
    "    history_df = pd.DataFrame(rows)\n",
    "    display(history_df)\n",
    "\n",
    "best_metric = results.get(\"best_metric\")\n",
    "best_epoch = results.get(\"best_epoch\")\n",
    "if best_metric is not None and best_epoch is not None:\n",
    "    print(f\"Best validation metric đạt {best_metric:.4f} tại epoch {best_epoch}\")\n",
    "\n",
    "plot_path = Path(results.get(\"training_plot\", \"\"))\n",
    "if plot_path.exists():\n",
    "    display(Image(filename=str(plot_path)))\n",
    "elif train_history:\n",
    "    inline_plot = Path(\"training_curves_inline.png\")\n",
    "    plot_training_curves(history, str(inline_plot))\n",
    "    if inline_plot.exists():\n",
    "        display(Image(filename=str(inline_plot)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}